<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Predicting Outcomes for New Data â€¢ mlr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/yeti/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">mlr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../articles/mlr.html">Get Started</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/task.html">Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learners.html">Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/predict.html">Predict</a>
    </li>
    <li>
      <a href="../../articles/tutorial/performance.html">Performance</a>
    </li>
    <li>
      <a href="../../articles/tutorial/resample.html">Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/tune.html">Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/benchmark_experiments.html">Benchmark Experiments</a>
    </li>
    <li>
      <a href="../../articles/tutorial/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/visualization.html">Visualization</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/bagging.html">Generic Bagging</a>
    </li>
  </ul>
</li>
<li class="dropdown-header">Extend</li>
<li class="dropdown-header">Appendix</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mlr-org/mlr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Predicting Outcomes for New Data</h1>
            
          </div>

    
    
<div class="contents">
<p>Predicting the target values for new observations is implemented the same way as most of the other predict methods in <strong>R</strong>. In general, all you need to do is call <a href="&amp;predict.WrappedModel">predict</a> on the object returned by [&amp;train] and pass the data you want predictions for.</p>
<p>There are two ways to pass the data:</p>
<ul>
<li>Either pass the [&amp;Task] via the <code>task</code> argument or</li>
<li>pass a <a href="&amp;base::data.frame">data.frame</a> via the <code>newdata</code> argument.</li>
</ul>
<p>The first way is preferable if you want predictions for data already included in a [&amp;Task].</p>
<p>Just as [&amp;train], the <a href="&amp;predict.WrappedModel">predict</a> function has a <code>subset</code> argument, so you can set aside different portions of the data in [&amp;Task] for training and prediction (more advanced methods for splitting the data in train and test set are described in the <a href="resample.md">section on resampling</a>).</p>
<p>In the following example we fit a <a href="&amp;gbm::gbm">gradient boosting machine</a> to every second observation of the <a href="&amp;mlbench::BostonHousing">BostonHousing</a> data set and make predictions on the remaining data in [&amp;bh.task].</p>
<pre class="sourceCode r" id="cb1"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">n =<span class="st"> </span><span class="kw"><a href="../../reference/getTaskSize.html">getTaskSize</a></span>(bh.task)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">train.set =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, n, <span class="dt">by =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">test.set =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">2</span>, n, <span class="dt">by =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"regr.gbm"</span>, <span class="dt">n.trees =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, bh.task, <span class="dt">subset =</span> train.set)</a>
<a class="sourceLine" id="cb1-6" data-line-number="6"></a>
<a class="sourceLine" id="cb1-7" data-line-number="7">task.pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">task =</span> bh.task, <span class="dt">subset =</span> test.set)</a>
<a class="sourceLine" id="cb1-8" data-line-number="8">task.pred</a></code></pre>
<pre><code>## Prediction: 253 observations
## predict.type: response
## threshold: 
## time: 0.00
##    id truth response
## 2   2  21.6 22.26829
## 4   4  33.4 23.16790
## 6   6  28.7 22.34407
## 8   8  27.1 22.14074
## 10 10  18.9 22.14074
## 12 12  18.9 22.14074
## ... (#rows: 253, #cols: 3)</code></pre>
<p>The second way is useful if you want to predict data not included in the [&amp;Task].</p>
<p>Here we cluster the <code>iris</code> data set without the target variable. All observations with an odd index are included in the [&amp;Task] and used for training. Predictions are made for the remaining observations.</p>
<pre class="sourceCode r" id="cb3"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">n =<span class="st"> </span><span class="kw">nrow</span>(iris)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">iris.train =<span class="st"> </span>iris[<span class="kw">seq</span>(<span class="dv">1</span>, n, <span class="dt">by =</span> <span class="dv">2</span>), <span class="dv">-5</span>]</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">iris.test =<span class="st"> </span>iris[<span class="kw">seq</span>(<span class="dv">2</span>, n, <span class="dt">by =</span> <span class="dv">2</span>), <span class="dv">-5</span>]</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">task =<span class="st"> </span><span class="kw"><a href="../../reference/Task.html">makeClusterTask</a></span>(<span class="dt">data =</span> iris.train)</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(<span class="st">"cluster.kmeans"</span>, task)</a>
<a class="sourceLine" id="cb3-6" data-line-number="6"></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">newdata.pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">newdata =</span> iris.test)</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">newdata.pred</a></code></pre>
<pre><code>## Prediction: 75 observations
## predict.type: response
## threshold: 
## time: 0.00
##    response
## 2         2
## 4         2
## 6         2
## 8         2
## 10        2
## 12        2
## ... (#rows: 75, #cols: 1)</code></pre>
<p>Note that for supervised learning you do not have to remove the target columns from the data. These columns are automatically removed prior to calling the underlying <code>predict</code> method of the learner.</p>
<section id="accessing-the-prediction" class="level2"><h2>Accessing the prediction</h2>
<p>Function [&amp;predict] returns a named <a href="&amp;base::list">list</a> of class [&amp;Prediction]. Its most important element is <code>$data</code> which is a <a href="&amp;base::data.frame">data.frame</a> that contains columns with the true values of the target variable (in case of supervised learning problems) and the predictions. Use <a href="&amp;Prediction">as.data.frame</a> for direct access.</p>
<p>In the following the predictions on the <a href="&amp;mlbench::BostonHousing">BostonHousing</a> and the <a href="&amp;datasets::iris">iris</a> data sets are shown. As you may recall, the predictions in the first case were made from a [&amp;Task] and in the second case from a <a href="&amp;base::data.frame">data.frame</a>.</p>
<pre class="sourceCode r" id="cb5"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">## Result of predict with data passed via task argument</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="kw">head</span>(<span class="kw">as.data.frame</span>(task.pred))</a></code></pre>
<pre><code>##    id truth response
## 2   2  21.6 22.26829
## 4   4  33.4 23.16790
## 6   6  28.7 22.34407
## 8   8  27.1 22.14074
## 10 10  18.9 22.14074
## 12 12  18.9 22.14074</code></pre>
<pre class="sourceCode r" id="cb7"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">## Result of predict with data passed via newdata argument</a>
<a class="sourceLine" id="cb7-2" data-line-number="2"><span class="kw">head</span>(<span class="kw">as.data.frame</span>(newdata.pred))</a></code></pre>
<pre><code>##    response
## 2         2
## 4         2
## 6         2
## 8         2
## 10        2
## 12        2</code></pre>
<p>As you can see when predicting from a [&amp;Task], the resulting <a href="&amp;base::data.frame">data.frame</a> contains an additional column, called <code>id</code>, which tells us which element in the original data set the prediction corresponds to.</p>
<p>A direct way to access the true and predicted values of the target variable(s) is provided by functions <a href="&amp;getPredictionResponse">getPredictionTruth</a> and [&amp;getPredictionResponse].</p>
<pre class="sourceCode r" id="cb9"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">head</span>(<span class="kw"><a href="../../reference/getPredictionResponse.html">getPredictionTruth</a></span>(task.pred))</a></code></pre>
<pre><code>## [1] 21.6 33.4 28.7 27.1 18.9 18.9</code></pre>
<pre class="sourceCode r" id="cb11"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">head</span>(<span class="kw"><a href="../../reference/getPredictionResponse.html">getPredictionResponse</a></span>(task.pred))</a></code></pre>
<pre><code>## [1] 22.26829 23.16790 22.34407 22.14074 22.14074 22.14074</code></pre>
<section id="regression-extracting-standard-errors" class="level3"><h3>Regression: Extracting standard errors</h3>
<p>Some learners provide standard errors for predictions, which can be accessed in [%mlr]. An overview is given by calling the function [&amp;listLearners] and setting <code>properties = "se"</code>. By assigning <code>FALSE</code> to <code>check.packages</code> learners from packages which are not installed will be included in the overview.</p>
<pre class="sourceCode r" id="cb13"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw"><a href="../../reference/listLearners.html">listLearners</a></span>(<span class="st">"regr"</span>, <span class="dt">check.packages =</span> <span class="ot">FALSE</span>, <span class="dt">properties =</span> <span class="st">"se"</span>)[<span class="kw">c</span>(<span class="st">"class"</span>, <span class="st">"name"</span>)]</a></code></pre>
<pre><code>## Warning in listLearners.character("regr", check.packages = FALSE, properties = "se"): The following learners could not be constructed, probably because their packages are not installed:
## classif.bartMachine,classif.extraTrees,regr.bartMachine,regr.extraTrees
## Check ?learners to see which packages you need or install mlr with all suggestions.</code></pre>
<pre><code>##          class
## 1   regr.bcart
## 2     regr.bgp
## 3  regr.bgpllm
## 4     regr.blm
## 5    regr.btgp
## 6 regr.btgpllm
##                                                                      name
## 1                                                           Bayesian CART
## 2                                               Bayesian Gaussian Process
## 3       Bayesian Gaussian Process with jumps to the Limiting Linear Model
## 4                                                   Bayesian Linear Model
## 5                                         Bayesian Treed Gaussian Process
## 6 Bayesian Treed Gaussian Process with jumps to the Limiting Linear Model
## ... (#rows: 16, #cols: 2)</code></pre>
<p>In this example we train a <a href="&amp;stats::lm">linear regression model</a> on the <a href="&amp;bh.task">Boston Housing</a> dataset. In order to calculate standard errors set the <code>predict.type</code> to <code>"se"</code>:</p>
<pre class="sourceCode r" id="cb16"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">## Create learner and specify predict.type</a>
<a class="sourceLine" id="cb16-2" data-line-number="2">lrn.lm =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"regr.lm"</span>, <span class="dt">predict.type =</span> <span class="st">'se'</span>)</a>
<a class="sourceLine" id="cb16-3" data-line-number="3">mod.lm =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn.lm, bh.task, <span class="dt">subset =</span> train.set)</a>
<a class="sourceLine" id="cb16-4" data-line-number="4">task.pred.lm =<span class="st"> </span><span class="kw">predict</span>(mod.lm, <span class="dt">task =</span> bh.task, <span class="dt">subset =</span> test.set)</a>
<a class="sourceLine" id="cb16-5" data-line-number="5">task.pred.lm</a></code></pre>
<pre><code>## Prediction: 253 observations
## predict.type: se
## threshold: 
## time: 0.00
##    id truth response        se
## 2   2  21.6 24.83734 0.7501615
## 4   4  33.4 28.38206 0.8742590
## 6   6  28.7 25.16725 0.8652139
## 8   8  27.1 19.38145 1.1963265
## 10 10  18.9 18.66449 1.1793944
## 12 12  18.9 21.25802 1.0727918
## ... (#rows: 253, #cols: 4)</code></pre>
<p>The standard errors can then be extracted using [&amp;getPredictionSE].</p>
<pre class="sourceCode r" id="cb18"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">head</span>(<span class="kw"><a href="../../reference/getPredictionResponse.html">getPredictionSE</a></span>(task.pred.lm))</a></code></pre>
<pre><code>## [1] 0.7501615 0.8742590 0.8652139 1.1963265 1.1793944 1.0727918</code></pre>
</section><section id="classification-and-clustering-extracting-probabilities" class="level3"><h3>Classification and clustering: Extracting probabilities</h3>
<p>The predicted probabilities can be extracted from the [&amp;Prediction] using function [&amp;getPredictionProbabilities]. Here is another cluster analysis example. We use <a href="&amp;e1071::cmeans">fuzzy c-means clustering</a> on the <a href="&amp;datasets::mtcars">mtcars</a> data set.</p>
<pre class="sourceCode r" id="cb20"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"cluster.cmeans"</span>, <span class="dt">predict.type =</span> <span class="st">"prob"</span>)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, mtcars.task)</a>
<a class="sourceLine" id="cb20-3" data-line-number="3"></a>
<a class="sourceLine" id="cb20-4" data-line-number="4">pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">task =</span> mtcars.task)</a>
<a class="sourceLine" id="cb20-5" data-line-number="5"><span class="kw">head</span>(<span class="kw"><a href="../../reference/getPredictionProbabilities.html">getPredictionProbabilities</a></span>(pred))</a></code></pre>
<pre><code>##                            1           2
## Mazda RX4         0.97960030 0.020399704
## Mazda RX4 Wag     0.97964051 0.020359488
## Datsun 710        0.99265841 0.007341593
## Hornet 4 Drive    0.54295605 0.457043948
## Hornet Sportabout 0.01870961 0.981290392
## Valiant           0.75749192 0.242508083</code></pre>
<p>For <em>classification problems</em> there are some more things worth mentioning. By default, class labels are predicted.</p>
<pre class="sourceCode r" id="cb22"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">## Linear discriminant analysis on the iris data set</a>
<a class="sourceLine" id="cb22-2" data-line-number="2">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(<span class="st">"classif.lda"</span>, <span class="dt">task =</span> iris.task)</a>
<a class="sourceLine" id="cb22-3" data-line-number="3"></a>
<a class="sourceLine" id="cb22-4" data-line-number="4">pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">task =</span> iris.task)</a>
<a class="sourceLine" id="cb22-5" data-line-number="5">pred</a></code></pre>
<pre><code>## Prediction: 150 observations
## predict.type: response
## threshold: 
## time: 0.00
##   id  truth response
## 1  1 setosa   setosa
## 2  2 setosa   setosa
## 3  3 setosa   setosa
## 4  4 setosa   setosa
## 5  5 setosa   setosa
## 6  6 setosa   setosa
## ... (#rows: 150, #cols: 3)</code></pre>
<p>In order to get predicted posterior probabilities we have to create a <a href="&amp;makeLearner">Learner</a> with the appropriate <code>predict.type</code>.</p>
<pre class="sourceCode r" id="cb24"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.rpart"</span>, <span class="dt">predict.type =</span> <span class="st">"prob"</span>)</a>
<a class="sourceLine" id="cb24-2" data-line-number="2">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, iris.task)</a>
<a class="sourceLine" id="cb24-3" data-line-number="3"></a>
<a class="sourceLine" id="cb24-4" data-line-number="4">pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">newdata =</span> iris)</a>
<a class="sourceLine" id="cb24-5" data-line-number="5"><span class="kw">head</span>(<span class="kw">as.data.frame</span>(pred))</a></code></pre>
<pre><code>##    truth prob.setosa prob.versicolor prob.virginica response
## 1 setosa           1               0              0   setosa
## 2 setosa           1               0              0   setosa
## 3 setosa           1               0              0   setosa
## 4 setosa           1               0              0   setosa
## 5 setosa           1               0              0   setosa
## 6 setosa           1               0              0   setosa</code></pre>
<p>In addition to the probabilities, class labels are predicted by choosing the class with the maximum probability and breaking ties at random.</p>
<p>As mentioned above, the predicted posterior probabilities can be accessed via the [&amp;getPredictionProbabilities] function.</p>
<pre class="sourceCode r" id="cb26"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1"><span class="kw">head</span>(<span class="kw"><a href="../../reference/getPredictionProbabilities.html">getPredictionProbabilities</a></span>(pred))</a></code></pre>
<pre><code>##   setosa versicolor virginica
## 1      1          0         0
## 2      1          0         0
## 3      1          0         0
## 4      1          0         0
## 5      1          0         0
## 6      1          0         0</code></pre>
</section><section id="classification-confusion-matrix" class="level3"><h3>Classification: Confusion matrix</h3>
<p>A confusion matrix can be obtained by calling [&amp;calculateConfusionMatrix]. The columns represent predicted and the rows true class labels.</p>
<pre class="sourceCode r" id="cb28"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="kw"><a href="../../reference/calculateConfusionMatrix.html">calculateConfusionMatrix</a></span>(pred)</a></code></pre>
<pre><code>##             predicted
## true         setosa versicolor virginica -err.-
##   setosa         50          0         0      0
##   versicolor      0         49         1      1
##   virginica       0          5        45      5
##   -err.-          0          5         1      6</code></pre>
<p>You can see the number of correctly classified observations on the diagonal of the matrix. Misclassified observations are on the off-diagonal. The total number of errors for single (true and predicted) classes is shown in the <code>-err.-</code> row and column, respectively.</p>
<p>To get relative frequencies additional to the absolute numbers we can set <code>relative = TRUE</code>.</p>
<pre class="sourceCode r" id="cb30"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1">conf.matrix =<span class="st"> </span><span class="kw"><a href="../../reference/calculateConfusionMatrix.html">calculateConfusionMatrix</a></span>(pred, <span class="dt">relative =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb30-2" data-line-number="2">conf.matrix</a></code></pre>
<pre><code>## Relative confusion matrix (normalized by row/column):
##             predicted
## true         setosa    versicolor virginica -err.-   
##   setosa     1.00/1.00 0.00/0.00  0.00/0.00 0.00     
##   versicolor 0.00/0.00 0.98/0.91  0.02/0.02 0.02     
##   virginica  0.00/0.00 0.10/0.09  0.90/0.98 0.10     
##   -err.-          0.00      0.09       0.02 0.04     
## 
## 
## Absolute confusion matrix:
##             predicted
## true         setosa versicolor virginica -err.-
##   setosa         50          0         0      0
##   versicolor      0         49         1      1
##   virginica       0          5        45      5
##   -err.-          0          5         1      6</code></pre>
<p>It is possible to normalize by either row or column, therefore every element of the above relative confusion matrix contains two values. The first is the relative frequency grouped by row (the true label) and the second value grouped by column (the predicted label).</p>
<p>If you want to access the relative values directly you can do this through the <code>$relative.row</code> and <code>$relative.col</code> members of the returned object <code>conf.matrix</code>. For more details see the [&amp;ConfusionMatrix] documentation page.</p>
<pre class="sourceCode r" id="cb32"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1">conf.matrix<span class="op">$</span>relative.row</a></code></pre>
<pre><code>##            setosa versicolor virginica -err-
## setosa          1       0.00      0.00  0.00
## versicolor      0       0.98      0.02  0.02
## virginica       0       0.10      0.90  0.10</code></pre>
<p>Finally, we can also add the absolute number of observations for each predicted and true class label to the matrix (both absolute and relative) by setting <code>sums = TRUE</code>.</p>
<pre class="sourceCode r" id="cb34"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1"><span class="kw"><a href="../../reference/calculateConfusionMatrix.html">calculateConfusionMatrix</a></span>(pred, <span class="dt">relative =</span> <span class="ot">TRUE</span>, <span class="dt">sums =</span> <span class="ot">TRUE</span>)</a></code></pre>
<pre><code>## Relative confusion matrix (normalized by row/column):
##             predicted
## true         setosa    versicolor virginica -err.-    -n- 
##   setosa     1.00/1.00 0.00/0.00  0.00/0.00 0.00      50  
##   versicolor 0.00/0.00 0.98/0.91  0.02/0.02 0.02      54  
##   virginica  0.00/0.00 0.10/0.09  0.90/0.98 0.10      46  
##   -err.-          0.00      0.09       0.02 0.04      &lt;NA&gt;
##   -n-        50        50         50        &lt;NA&gt;      150 
## 
## 
## Absolute confusion matrix:
##            setosa versicolor virginica -err.- -n-
## setosa         50          0         0      0  50
## versicolor      0         49         1      1  50
## virginica       0          5        45      5  50
## -err.-          0          5         1      6  NA
## -n-            50         54        46     NA 150</code></pre>
</section></section><section id="classification-adjusting-the-decision-threshold" class="level2"><h2>Classification: Adjusting the decision threshold</h2>
<p>We can set the threshold value that is used to map the predicted posterior probabilities to class labels. Note that for this purpose we need to create a <a href="&amp;makeLearner">Learner</a> that predicts probabilities. For binary classification, the threshold determines when the <em>positive</em> class is predicted. The default is 0.5. Now, we set the threshold for the positive class to 0.9 (that is, an example is assigned to the positive class if its posterior probability exceeds 0.9). Which of the two classes is the positive one can be seen by accessing the [&amp;Task]. To illustrate binary classification, we use the <a href="&amp;mlbench::Sonar">Sonar</a> data set from the [%mlbench] package.</p>
<pre class="sourceCode r" id="cb36"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.rpart"</span>, <span class="dt">predict.type =</span> <span class="st">"prob"</span>)</a>
<a class="sourceLine" id="cb36-2" data-line-number="2">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, <span class="dt">task =</span> sonar.task)</a>
<a class="sourceLine" id="cb36-3" data-line-number="3"></a>
<a class="sourceLine" id="cb36-4" data-line-number="4">## Label of the positive class</a>
<a class="sourceLine" id="cb36-5" data-line-number="5"><span class="kw"><a href="../../reference/getTaskDesc.html">getTaskDesc</a></span>(sonar.task)<span class="op">$</span>positive</a></code></pre>
<pre><code>## [1] "M"</code></pre>
<pre class="sourceCode r" id="cb38"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1">## Default threshold</a>
<a class="sourceLine" id="cb38-2" data-line-number="2">pred1 =<span class="st"> </span><span class="kw">predict</span>(mod, sonar.task)</a>
<a class="sourceLine" id="cb38-3" data-line-number="3">pred1<span class="op">$</span>threshold</a></code></pre>
<pre><code>##   M   R 
## 0.5 0.5</code></pre>
<pre class="sourceCode r" id="cb40"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1">## Set the threshold value for the positive class</a>
<a class="sourceLine" id="cb40-2" data-line-number="2">pred2 =<span class="st"> </span><span class="kw"><a href="../../reference/setThreshold.html">setThreshold</a></span>(pred1, <span class="fl">0.9</span>)</a>
<a class="sourceLine" id="cb40-3" data-line-number="3">pred2<span class="op">$</span>threshold</a></code></pre>
<pre><code>##   M   R 
## 0.9 0.1</code></pre>
<pre class="sourceCode r" id="cb42"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1">pred2</a></code></pre>
<pre><code>## Prediction: 208 observations
## predict.type: prob
## threshold: M=0.90,R=0.10
## time: 0.01
##   id truth    prob.M    prob.R response
## 1  1     R 0.1060606 0.8939394        R
## 2  2     R 0.7333333 0.2666667        R
## 3  3     R 0.0000000 1.0000000        R
## 4  4     R 0.1060606 0.8939394        R
## 5  5     R 0.9250000 0.0750000        M
## 6  6     R 0.0000000 1.0000000        R
## ... (#rows: 208, #cols: 5)</code></pre>
<pre class="sourceCode r" id="cb44"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1">## We can also set the effect in the confusion matrix</a>
<a class="sourceLine" id="cb44-2" data-line-number="2"><span class="kw"><a href="../../reference/calculateConfusionMatrix.html">calculateConfusionMatrix</a></span>(pred1)</a></code></pre>
<pre><code>##         predicted
## true      M  R -err.-
##   M      95 16     16
##   R      10 87     10
##   -err.- 10 16     26</code></pre>
<pre class="sourceCode r" id="cb46"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="kw"><a href="../../reference/calculateConfusionMatrix.html">calculateConfusionMatrix</a></span>(pred2)</a></code></pre>
<pre><code>##         predicted
## true      M  R -err.-
##   M      84 27     27
##   R       6 91      6
##   -err.-  6 27     33</code></pre>
<p>Note that in the binary case [&amp;getPredictionProbabilities] by default extracts the posterior probabilities of the positive class only.</p>
<pre class="sourceCode r" id="cb48"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1"><span class="kw">head</span>(<span class="kw"><a href="../../reference/getPredictionProbabilities.html">getPredictionProbabilities</a></span>(pred1))</a></code></pre>
<pre><code>## [1] 0.1060606 0.7333333 0.0000000 0.1060606 0.9250000 0.0000000</code></pre>
<pre class="sourceCode r" id="cb50"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1">## But we can change that, too</a>
<a class="sourceLine" id="cb50-2" data-line-number="2"><span class="kw">head</span>(<span class="kw"><a href="../../reference/getPredictionProbabilities.html">getPredictionProbabilities</a></span>(pred1, <span class="dt">cl =</span> <span class="kw">c</span>(<span class="st">"M"</span>, <span class="st">"R"</span>)))</a></code></pre>
<pre><code>##           M         R
## 1 0.1060606 0.8939394
## 2 0.7333333 0.2666667
## 3 0.0000000 1.0000000
## 4 0.1060606 0.8939394
## 5 0.9250000 0.0750000
## 6 0.0000000 1.0000000</code></pre>
<p>It works similarly for multiclass classification. The threshold has to be given by a named vector specifying the values by which each probability will be divided. The class with the maximum resulting value is then selected.</p>
<pre class="sourceCode r" id="cb52"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.rpart"</span>, <span class="dt">predict.type =</span> <span class="st">"prob"</span>)</a>
<a class="sourceLine" id="cb52-2" data-line-number="2">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, iris.task)</a>
<a class="sourceLine" id="cb52-3" data-line-number="3">pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">newdata =</span> iris)</a>
<a class="sourceLine" id="cb52-4" data-line-number="4">pred<span class="op">$</span>threshold</a></code></pre>
<pre><code>##     setosa versicolor  virginica 
##  0.3333333  0.3333333  0.3333333</code></pre>
<pre class="sourceCode r" id="cb54"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1"><span class="kw">table</span>(<span class="kw">as.data.frame</span>(pred)<span class="op">$</span>response)</a></code></pre>
<pre><code>## 
##     setosa versicolor  virginica 
##         50         54         46</code></pre>
<pre class="sourceCode r" id="cb56"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1">pred =<span class="st"> </span><span class="kw"><a href="../../reference/setThreshold.html">setThreshold</a></span>(pred, <span class="kw">c</span>(<span class="dt">setosa =</span> <span class="fl">0.01</span>, <span class="dt">versicolor =</span> <span class="dv">50</span>, <span class="dt">virginica =</span> <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb56-2" data-line-number="2">pred<span class="op">$</span>threshold</a></code></pre>
<pre><code>##     setosa versicolor  virginica 
##       0.01      50.00       1.00</code></pre>
<pre class="sourceCode r" id="cb58"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" data-line-number="1"><span class="kw">table</span>(<span class="kw">as.data.frame</span>(pred)<span class="op">$</span>response)</a></code></pre>
<pre><code>## 
##     setosa versicolor  virginica 
##         50          0        100</code></pre>
<p>If you are interested in tuning the threshold (vector) have a look at the section about <a href="roc_analysis.md">performance curves and threshold tuning</a>.</p>
</section><section id="visualizing-the-prediction" class="level2"><h2>Visualizing the prediction</h2>
<p>The function [&amp;plotLearnerPrediction] allows to visualize predictions, e.g., for teaching purposes or exploring models. It trains the chosen learning method for 1 or 2 selected features and then displays the predictions with <a href="&amp;ggplot2::ggplot">ggplot</a>.</p>
<p>For <em>classification</em>, we get a scatter plot of 2 features (by default the first 2 in the data set). The type of symbol shows the true class labels of the data points. Symbols with white border indicate misclassified observations. The posterior probabilities (if the learner under consideration supports this) are represented by the background color where higher saturation means larger probabilities.</p>
<p>The plot title displays the ID of the <a href="&amp;makeLearner">Learner</a> (in the following example CART), its parameters, its training performance and its cross-validation performance. <a href="measures.md">mmce</a> stands for <em>mean misclassification error</em>, i.e., the error rate. See the sections on <a href="performance.md">performance</a> and <a href="resample.md">resampling</a> for further explanations.</p>
<pre class="sourceCode r" id="cb60"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.rpart"</span>, <span class="dt">id =</span> <span class="st">"CART"</span>)</a>
<a class="sourceLine" id="cb60-2" data-line-number="2"><span class="kw"><a href="../../reference/plotLearnerPrediction.html">plotLearnerPrediction</a></span>(lrn, <span class="dt">task =</span> iris.task)</a></code></pre>
<p><img src="predict_files/figure-html/unnamed-chunk-20-1.png" width="672"></p>
<p>For <em>clustering</em> we also get a scatter plot of two selected features. The color of the points indicates the predicted cluster.</p>
<pre class="sourceCode r" id="cb61"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" data-line-number="1">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"cluster.kmeans"</span>)</a>
<a class="sourceLine" id="cb61-2" data-line-number="2"><span class="kw"><a href="../../reference/plotLearnerPrediction.html">plotLearnerPrediction</a></span>(lrn, <span class="dt">task =</span> mtcars.task, <span class="dt">features =</span> <span class="kw">c</span>(<span class="st">"disp"</span>, <span class="st">"drat"</span>), <span class="dt">cv =</span> <span class="dv">0</span>)</a></code></pre>
<pre><code>## 
## This is package 'modeest' written by P. PONCET.
## For a complete list of functions, use 'library(help = "modeest")' or 'help.start()'.</code></pre>
<p><img src="predict_files/figure-html/unnamed-chunk-21-1.png" width="672"></p>
<p>For <em>regression</em>, there are two types of plots. The 1D plot shows the target values in relation to a single feature, the regression curve and, if the chosen learner supports this, the estimated standard error.</p>
<pre class="sourceCode r" id="cb63"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" data-line-number="1"><span class="kw"><a href="../../reference/plotLearnerPrediction.html">plotLearnerPrediction</a></span>(<span class="st">"regr.lm"</span>, <span class="dt">features =</span> <span class="st">"lstat"</span>, <span class="dt">task =</span> bh.task)</a></code></pre>
<p><img src="predict_files/figure-html/unnamed-chunk-22-1.png" width="672"></p>
<p>The 2D variant, as in the classification case, generates a scatter plot of 2 features. The fill color of the dots illustrates the value of the target variable <code>"medv"</code>, the background colors show the estimated mean. The plot does not represent the estimated standard error.</p>
<pre class="sourceCode r" id="cb64"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" data-line-number="1"><span class="kw"><a href="../../reference/plotLearnerPrediction.html">plotLearnerPrediction</a></span>(<span class="st">"regr.lm"</span>, <span class="dt">features =</span> <span class="kw">c</span>(<span class="st">"lstat"</span>, <span class="st">"rm"</span>), <span class="dt">task =</span> bh.task)</a></code></pre>
<p><img src="predict_files/figure-html/unnamed-chunk-23-1.png" width="672"></p>
</section>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#accessing-the-prediction">Accessing the prediction</a></li>
      <li><a href="#classification-adjusting-the-decision-threshold">Classification: Adjusting the decision threshold</a></li>
      <li><a href="#visualizing-the-prediction">Visualizing the prediction</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
