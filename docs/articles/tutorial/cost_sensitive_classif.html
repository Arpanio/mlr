<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Cost-Sensitive Classification â€¢ mlr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/yeti/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">mlr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../articles/mlr.html">Get Started</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Basics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/task.html">Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learners.html">Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/predict.html">Predict</a>
    </li>
    <li>
      <a href="../../articles/tutorial/performance.html">Performance</a>
    </li>
    <li>
      <a href="../../articles/tutorial/resample.html">Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/tune.html">Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/benchmark_experiments.html">Benchmark Experiments</a>
    </li>
    <li>
      <a href="../../articles/tutorial/parallelization.html">Parallelization</a>
    </li>
    <li>
      <a href="../../articles/tutorial/visualization.html">Visualization</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Advanced
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/configuring.html">Configuration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/wrapper.html">Wrapped Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/preproc.html">Preprocessing</a>
    </li>
    <li>
      <a href="../../articles/tutorial/impute.html">Imputation</a>
    </li>
    <li>
      <a href="../../articles/tutorial/bagging.html">Generic Bagging</a>
    </li>
    <li>
      <a href="../../articles/tutorial/advanced_tune.html">Advanced Tuning</a>
    </li>
    <li>
      <a href="../../articles/tutorial/feature_selection.html">Feature Selection</a>
    </li>
    <li>
      <a href="../../articles/tutorial/nested_resampling.html">Nested Resampling</a>
    </li>
    <li>
      <a href="../../articles/tutorial/cost_sensitive_classif.html">Cost-Sensitive Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/imbalanced_classification_problems.html">Imbalanced Classification Problems</a>
    </li>
    <li>
      <a href="../../articles/tutorial/roc_analysis.html">ROC Analysis and Performance Curves</a>
    </li>
    <li>
      <a href="../../articles/tutorial/multilabel.html">Multilabel Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial/learning_curve_analysis.html">Learning Curve Analysis</a>
    </li>
    <li>
      <a href="../../articles/tutorial/partial_dependence.html">Partial Dependence Plots</a>
    </li>
    <li>
      <a href="../../articles/tutorial/classifier_calibration.html">Classifier Calibration</a>
    </li>
    <li>
      <a href="../../articles/tutorial/hyperparameter_tuning_effects.html">Hyperparameter Tuning Effects</a>
    </li>
    <li>
      <a href="../../articles/tutorial/out_of_bag_predictions.html">Out-of-Bag Predictions</a>
    </li>
    <li>
      <a href="../../articles/tutorial/handling_of_spatial_data.html">Handling of Spatial Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Extend
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/custom_learners.html">Create Custom Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/custom_measures.html">Create Custom Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_imputation.html">Create Imputation Methods</a>
    </li>
    <li>
      <a href="../../articles/tutorial/create_filter.html">Create Custom Filters</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Appendix
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/tutorial/example_tasks.html">Example Tasks</a>
    </li>
    <li>
      <a href="../../articles/tutorial/integrated_learners.html">Integrated Learners</a>
    </li>
    <li>
      <a href="../../articles/tutorial/implemented_measures.html">Implemented Measures</a>
    </li>
    <li>
      <a href="../../articles/tutorial/filter_methods.html">Integrated Filter Methods</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mlr-org/mlr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form" role="search" method="GET" action="../../search.html">
        <div class="input-group">
          <input type="text" class="form-control" placeholder="Search" id="search" name="search">
</div>
        <button type="submit" class="btn btn-default">
          <i class="glyphicon glyphicon-search"></i>
        </button>
      </form>
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Cost-Sensitive Classification</h1>
            
          </div>

    
    
<div class="contents">
<p>In <em>regular classification</em> the aim is to minimize the misclassification rate and thus all types of misclassification errors are deemed equally severe. A more general setting is <em>cost-sensitive classification</em> where the costs caused by different kinds of errors are not assumed to be equal and the objective is to minimize the expected costs.</p>
<p>In case of <em>class-dependent costs</em> the costs depend on the true and predicted class label. The costs <span class="math inline">\(c(k, l)\)</span> for predicting class <span class="math inline">\(k\)</span> if the true label is <span class="math inline">\(l\)</span> are usually organized into a <span class="math inline">\(K \times K\)</span> cost matrix where <span class="math inline">\(K\)</span> is the number of classes. Naturally, it is assumed that the cost of predicting the correct class label <span class="math inline">\(y\)</span> is minimal (that is <span class="math inline">\(c(y, y) \leq c(k, y)\)</span> for all <span class="math inline">\(k = 1,\ldots,K\)</span>).</p>
<p>A further generalization of this scenario are <em>example-dependent misclassification costs</em> where each example <span class="math inline">\((x, y)\)</span> is coupled with an individual cost vector of length <span class="math inline">\(K\)</span>. Its <span class="math inline">\(k\)</span>-th component expresses the cost of assigning <span class="math inline">\(x\)</span> to class <span class="math inline">\(k\)</span>. A real-world example is fraud detection where the costs do not only depend on the true and predicted status fraud/non-fraud, but also on the amount of money involved in each case. Naturally, the cost of predicting the true class label <span class="math inline">\(y\)</span> is assumed to be minimum. The true class labels are redundant information, as they can be easily inferred from the cost vectors. Moreover, given the cost vector, the expected costs do not depend on the true class label <span class="math inline">\(y\)</span>. The classification problem is therefore completely defined by the feature values <span class="math inline">\(x\)</span> and the corresponding cost vectors.</p>
<p>In the following we show ways to handle cost-sensitive classification problems in [%mlr]. Some of the functionality is currently experimental, and there may be changes in the future.</p>
<div id="class-dependent-misclassification-costs" class="section level2">
<h2 class="hasAnchor">
<a href="#class-dependent-misclassification-costs" class="anchor"></a>Class-dependent misclassification costs</h2>
<p>There are some classification methods that can accomodate misclassification costs directly. One example is <a href="&amp;rpart::rpart">rpart</a>.</p>
<p>Alternatively, we can use cost-insensitive methods and manipulate the predictions or the training data in order to take misclassification costs into account. [%mlr] supports <em>thresholding</em> and <em>rebalancing</em>.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Thresholding</strong>: The thresholds used to turn posterior probabilities into class labels are chosen such that the costs are minimized. This requires a <a href="&amp;makeLearner">Learner</a> that can predict posterior probabilities. During training the costs are not taken into account.</p></li>
<li>
<p><strong>Rebalancing</strong>: The idea is to change the proportion of the classes in the training data set in order to account for costs during training, either by <em>weighting</em> or by <em>sampling</em>. Rebalancing does not require that the <a href="&amp;makeLearner">Learner</a> can predict probabilities.</p>
<ol style="list-style-type: lower-roman">
<li><p>For <em>weighting</em> we need a <a href="&amp;makeLearner">Learner</a> that supports class weights or observation weights.</p></li>
<li><p>If the <a href="&amp;makeLearner">Learner</a> cannot deal with weights the proportion of classes can be changed by <em>over-</em> and <em>undersampling</em>.</p></li>
</ol>
</li>
</ol>
<p>We start with binary classification problems and afterwards deal with multi-class problems.</p>
<div id="binary-classification-problems" class="section level3">
<h3 class="hasAnchor">
<a href="#binary-classification-problems" class="anchor"></a>Binary classification problems</h3>
<p>The positive and negative classes are labeled <span class="math inline">\(1\)</span> and <span class="math inline">\(-1\)</span>, respectively, and we consider the following cost matrix where the rows indicate true classes and the columns predicted classes:</p>
<table class="table"><tbody>
<tr class="odd">
<td align="center">true/pred.</td>
<td align="center"><span class="math inline">\(+1\)</span></td>
<td align="center"><span class="math inline">\(-1\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(+1\)</span></td>
<td align="center"><span class="math inline">\(c(+1,+1)\)</span></td>
<td align="center"><span class="math inline">\(c(-1,+1)\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(-1\)</span></td>
<td align="center"><span class="math inline">\(c(+1,-1)\)</span></td>
<td align="center"><span class="math inline">\(c(-1,-1)\)</span></td>
</tr>
</tbody></table>
<p>Often, the diagonal entries are zero or the cost matrix is rescaled to achieve zeros in the diagonal (see for example <a href="http://machinelearning.org/archive/icml2008/papers/150.pdf">Oâ€™Brien et al, 2008</a>).</p>
<p>A well-known cost-sensitive classification problem is posed by the <a href="&amp;caret::GermanCredit">German Credit data set</a> (see also the <a href="https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)">UCI Machine Learning Repository</a>). The corresponding cost matrix (though <a href="http://www.cs.iastate.edu/~honavar/elkan.pdf">Elkan (2001)</a> argues that this matrix is economically unreasonable) is given as:</p>
<table class="table"><tbody>
<tr class="odd">
<td align="left">true/pred.</td>
<td align="center">Bad</td>
<td align="center">Good</td>
</tr>
<tr class="even">
<td align="left">Bad</td>
<td align="center">0</td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="left">Good</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
</tbody></table>
<p>As in the table above, the rows indicate true and the columns predicted classes.</p>
<p>In case of class-dependent costs it is sufficient to generate an ordinary <a href="&amp;Task">ClassifTask</a>. A <a href="&amp;Task">CostSensTask</a> is only needed if the costs are example-dependent. In the <strong>R</strong> code below we create the <a href="&amp;Task">ClassifTask</a>, remove two constant features from the data set and generate the cost matrix. Per default, Bad is the positive class.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(GermanCredit, <span class="dt">package =</span> <span class="st">"caret"</span>)
credit.task =<span class="st"> </span><span class="kw"><a href="../../reference/Task.html">makeClassifTask</a></span>(<span class="dt">data =</span> GermanCredit, <span class="dt">target =</span> <span class="st">"Class"</span>)
credit.task =<span class="st"> </span><span class="kw"><a href="../../reference/removeConstantFeatures.html">removeConstantFeatures</a></span>(credit.task)</code></pre></div>
<pre><code>## Removing 2 columns: Purpose.Vacation,Personal.Female.Single</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">credit.task</code></pre></div>
<pre><code>## Supervised task: GermanCredit
## Type: classif
## Target: Class
## Observations: 1000
## Features:
##    numerics     factors     ordered functionals 
##          59           0           0           0 
## Missings: FALSE
## Has weights: FALSE
## Has blocking: FALSE
## Is spatial: FALSE
## Classes: 2
##  Bad Good 
##  300  700 
## Positive class: Bad</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">costs =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">0</span>), <span class="dv">2</span>)
<span class="kw">colnames</span>(costs) =<span class="st"> </span><span class="kw">rownames</span>(costs) =<span class="st"> </span><span class="kw"><a href="../../reference/getTaskClassLevels.html">getTaskClassLevels</a></span>(credit.task)
costs</code></pre></div>
<pre><code>##      Bad Good
## Bad    0    5
## Good   1    0</code></pre>
<div id="thresholding" class="section level4">
<h4 class="hasAnchor">
<a href="#thresholding" class="anchor"></a>1. Thresholding</h4>
<p>We start by fitting a <a href="&amp;nnet::multinom">logistic regression model</a> to the <a href="&amp;caret::GermanCredit">German credit data set</a> and predict posterior probabilities.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Train and predict posterior probabilities
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">predict.type =</span> <span class="st">"prob"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, credit.task)
pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">task =</span> credit.task)
pred</code></pre></div>
<pre><code>## Prediction: 1000 observations
## predict.type: prob
## threshold: Bad=0.50,Good=0.50
## time: 0.01
##   id truth   prob.Bad prob.Good response
## 1  1  Good 0.03525092 0.9647491     Good
## 2  2   Bad 0.63222363 0.3677764      Bad
## 3  3  Good 0.02807414 0.9719259     Good
## 4  4  Good 0.25182703 0.7481730     Good
## 5  5   Bad 0.75193275 0.2480673      Bad
## 6  6  Good 0.26230149 0.7376985     Good
## ... (#rows: 1000, #cols: 5)</code></pre>
<p>The default thresholds for both classes are 0.5. But according to the cost matrix we should predict class Good only if we are very sure that Good is indeed the correct label. Therefore we should increase the threshold for class Good and decrease the threshold for class Bad.</p>
<div id="i--theoretical-thresholding" class="section level5">
<h5 class="hasAnchor">
<a href="#i--theoretical-thresholding" class="anchor"></a>i. Theoretical thresholding</h5>
<p>The theoretical threshold for the <em>positive</em> class can be calculated from the cost matrix as <span class="math display">\[t^* = \frac{c(+1,-1) - c(-1,-1)}{c(+1,-1) - c(+1,+1) + c(-1,+1) - c(-1,-1)}.\]</span> For more details see <a href="http://www.cs.iastate.edu/~honavar/elkan.pdf">Elkan (2001)</a>.</p>
<p>Below the theoretical threshold for the <a href="&amp;caret::GermanCredit">German credit example</a> is calculated and used to predict class labels. Since the diagonal of the cost matrix is zero the formula given above simplifies accordingly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Calculate the theoretical threshold for the positive class
th =<span class="st"> </span>costs[<span class="dv">2</span>,<span class="dv">1</span>]/(costs[<span class="dv">2</span>,<span class="dv">1</span>] +<span class="st"> </span>costs[<span class="dv">1</span>,<span class="dv">2</span>])
th</code></pre></div>
<pre><code>## [1] 0.1666667</code></pre>
<p>As you may recall you can change thresholds in [%mlr] either before training by using the <code>predict.threshold</code> option of [&amp;makeLearner] or after prediction by calling [&amp;setThreshold] on the [&amp;Prediction] object.</p>
<p>As we already have a prediction we use the [&amp;setThreshold] function. It returns an altered [&amp;Prediction] object with class predictions for the theoretical threshold.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Predict class labels according to the theoretical threshold
pred.th =<span class="st"> </span><span class="kw"><a href="../../reference/setThreshold.html">setThreshold</a></span>(pred, th)
pred.th</code></pre></div>
<pre><code>## Prediction: 1000 observations
## predict.type: prob
## threshold: Bad=0.17,Good=0.83
## time: 0.01
##   id truth   prob.Bad prob.Good response
## 1  1  Good 0.03525092 0.9647491     Good
## 2  2   Bad 0.63222363 0.3677764      Bad
## 3  3  Good 0.02807414 0.9719259     Good
## 4  4  Good 0.25182703 0.7481730      Bad
## 5  5   Bad 0.75193275 0.2480673      Bad
## 6  6  Good 0.26230149 0.7376985      Bad
## ... (#rows: 1000, #cols: 5)</code></pre>
<p>In order to calculate the average costs over the entire data set we first need to create a new performance <a href="&amp;makeMeasure">Measure</a>. This can be done through function [&amp;makeCostMeasure]. It is expected that the rows of the cost matrix indicate true and the columns predicted class labels.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">credit.costs =<span class="st"> </span><span class="kw"><a href="../../reference/makeCostMeasure.html">makeCostMeasure</a></span>(<span class="dt">id =</span> <span class="st">"credit.costs"</span>, <span class="dt">name =</span> <span class="st">"Credit costs"</span>, <span class="dt">costs =</span> costs,
  <span class="dt">best =</span> <span class="dv">0</span>, <span class="dt">worst =</span> <span class="dv">5</span>)
credit.costs</code></pre></div>
<pre><code>## Name: Credit costs
## Performance measure: credit.costs
## Properties: classif,classif.multi,req.pred,req.truth,predtype.response,predtype.prob
## Minimize: TRUE
## Best: 0; Worst: 5
## Aggregated by: test.mean
## Arguments: &lt;unnamed&gt;=&lt;matrix&gt;, &lt;unnamed&gt;=&lt;function&gt;
## Note:</code></pre>
<p>Then the average costs can be computed by function [&amp;performance]. Below we compare the average costs and the error rate (<a href="measures.md">mmce</a>) of the learning algorithm with both default thresholds 0.5 and theoretical thresholds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Performance with default thresholds 0.5
<span class="kw"><a href="../../reference/performance.html">performance</a></span>(pred, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce))</code></pre></div>
<pre><code>## credit.costs         mmce 
##        0.774        0.214</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Performance with theoretical thresholds
<span class="kw"><a href="../../reference/performance.html">performance</a></span>(pred.th, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce))</code></pre></div>
<pre><code>## credit.costs         mmce 
##        0.478        0.346</code></pre>
<p>These performance values may be overly optimistic as we used the same data set for training and prediction, and resampling strategies should be preferred. In the <strong>R</strong> code below we make use of the <code>predict.threshold</code> argument of [&amp;makeLearner] to set the threshold before doing a 3-fold cross-validation on the [&amp;credit.task]. Note that we create a <a href="&amp;makeResampleInstance">ResampleInstance</a> (<code>rin</code>) that is used throughout the next several code chunks to get comparable performance values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Cross-validated performance with theoretical thresholds
rin =<span class="st"> </span><span class="kw"><a href="../../reference/makeResampleInstance.html">makeResampleInstance</a></span>(<span class="st">"CV"</span>, <span class="dt">iters =</span> <span class="dv">3</span>, <span class="dt">task =</span> credit.task)
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">predict.type =</span> <span class="st">"prob"</span>, <span class="dt">predict.threshold =</span> th, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
r =<span class="st"> </span><span class="kw"><a href="../../reference/resample.html">resample</a></span>(lrn, credit.task, <span class="dt">resampling =</span> rin, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>## Resample Result
## Task: GermanCredit
## Learner: classif.multinom
## Aggr perf: credit.costs.test.mean=0.5689012,mmce.test.mean=0.3649847
## Runtime: 0.204722</code></pre>
<p>If we are also interested in the cross-validated performance for the default threshold values we can call [&amp;setThreshold] on the <a href="&amp;ResamplePrediction">resample prediction</a> <code>r$pred</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Cross-validated performance with default thresholds
<span class="kw"><a href="../../reference/performance.html">performance</a></span>(<span class="kw"><a href="../../reference/setThreshold.html">setThreshold</a></span>(r$pred, <span class="fl">0.5</span>), <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce))</code></pre></div>
<pre><code>## credit.costs         mmce 
##    0.9009668    0.2769896</code></pre>
<p>Theoretical thresholding is only reliable if the predicted posterior probabilities are correct. If there is bias the thresholds have to be shifted accordingly.</p>
<p>Useful in this regard is function [&amp;plotThreshVsPerf] that you can use to plot the average costs as well as any other performance measure versus possible threshold values for the positive class in <span class="math inline">\([0,1]\)</span>. The underlying data is generated by [&amp;generateThreshVsPerfData].</p>
<p>The following plots show the cross-validated costs and error rate (<a href="measures.md">mmce</a>). The theoretical threshold <code>th</code> calculated above is indicated by the vertical line. As you can see from the left-hand plot the theoretical threshold seems a bit large.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d =<span class="st"> </span><span class="kw"><a href="../../reference/generateThreshVsPerfData.html">generateThreshVsPerfData</a></span>(r, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce))
<span class="kw"><a href="../../reference/plotThreshVsPerf.html">plotThreshVsPerf</a></span>(d, <span class="dt">mark.th =</span> th)</code></pre></div>
<p><img src="cost_sensitive_classif_files/figure-html/unnamed-chunk-10-1.png" width="672"></p>
</div>
<div id="ii--empirical-thresholding" class="section level5">
<h5 class="hasAnchor">
<a href="#ii--empirical-thresholding" class="anchor"></a>ii. Empirical thresholding</h5>
<p>The idea of <em>empirical thresholding</em> (see <a href="http://sun0.cs.uca.edu/~ssheng/papers/AAAI06a.pdf">Sheng and Ling, 2006</a>) is to select cost-optimal threshold values for a given learning method based on the training data. In contrast to <em>theoretical thresholding</em> it suffices if the estimated posterior probabilities are order-correct.</p>
<p>In order to determine optimal threshold values you can use [%mlr]â€™s function [&amp;tuneThreshold]. As tuning the threshold on the complete training data set can lead to overfitting, you should use resampling strategies. Below we perform 3-fold cross-validation and use [&amp;tuneThreshold] to calculate threshold values with lowest average costs over the 3 test data sets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">predict.type =</span> <span class="st">"prob"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)

## 3-fold cross-validation
r =<span class="st"> </span><span class="kw"><a href="../../reference/resample.html">resample</a></span>(lrn, credit.task, <span class="dt">resampling =</span> rin, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>## Resample Result
## Task: GermanCredit
## Learner: classif.multinom
## Aggr perf: credit.costs.test.mean=0.9009668,mmce.test.mean=0.2769896
## Runtime: 0.206992</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Tune the threshold based on the predicted probabilities on the 3 test data sets
tune.res =<span class="st"> </span><span class="kw"><a href="../../reference/tuneThreshold.html">tuneThreshold</a></span>(<span class="dt">pred =</span> r$pred, <span class="dt">measure =</span> credit.costs)
tune.res</code></pre></div>
<pre><code>## $th
## [1] 0.1331617
## 
## $perf
## credit.costs 
##    0.5498912</code></pre>
<p>[&amp;tuneThreshold] returns the optimal threshold value for the positive class and the corresponding performance. As expected the tuned threshold is smaller than the theoretical threshold.</p>
</div>
</div>
<div id="rebalancing" class="section level4">
<h4 class="hasAnchor">
<a href="#rebalancing" class="anchor"></a>2. Rebalancing</h4>
<p>In order to minimize the average costs, observations from the less costly class should be given higher importance during training. This can be achieved by <em>weighting</em> the classes, provided that the learner under consideration has a â€˜class weightsâ€™ or an â€˜observation weightsâ€™ argument. To find out which learning methods support either type of weights have a look at the <a href="integrated_learners.md">list of integrated learners</a> in the Appendix or use [&amp;listLearners].</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Learners that accept observation weights
<span class="kw"><a href="../../reference/listLearners.html">listLearners</a></span>(<span class="st">"classif"</span>, <span class="dt">properties =</span> <span class="st">"weights"</span>)[<span class="kw">c</span>(<span class="st">"class"</span>, <span class="st">"package"</span>)]</code></pre></div>
<pre><code>##                class      package
## 1   classif.binomial        stats
## 2 classif.blackboost mboost,party
## 3        classif.C50          C50
## 4    classif.cforest        party
## 5      classif.ctree        party
## 6   classif.cvglmnet       glmnet
## ... (#rows: 25, #cols: 2)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Learners that can deal with class weights
<span class="kw"><a href="../../reference/listLearners.html">listLearners</a></span>(<span class="st">"classif"</span>, <span class="dt">properties =</span> <span class="st">"class.weights"</span>)[<span class="kw">c</span>(<span class="st">"class"</span>, <span class="st">"package"</span>)]</code></pre></div>
<pre><code>##                       class   package
## 1              classif.ksvm   kernlab
## 2  classif.LiblineaRL1L2SVC LiblineaR
## 3 classif.LiblineaRL1LogReg LiblineaR
## 4  classif.LiblineaRL2L1SVC LiblineaR
## 5 classif.LiblineaRL2LogReg LiblineaR
## 6    classif.LiblineaRL2SVC LiblineaR
## ... (#rows: 9, #cols: 2)</code></pre>
<p>Alternatively, <em>over- and undersampling</em> techniques can be used.</p>
<div id="i--weighting" class="section level5">
<h5 class="hasAnchor">
<a href="#i--weighting" class="anchor"></a>i. Weighting</h5>
<p>Just as <em>theoretical thresholds</em>, <em>theoretical weights</em> can be calculated from the cost matrix. If <span class="math inline">\(t\)</span> indicates the target threshold and <span class="math inline">\(t_0\)</span> the original threshold for the positive class the proportion of observations in the positive class has to be multiplied by <span class="math display">\[\frac{1-t}{t} \frac{t_0}{1-t_0}.\]</span> Alternatively, the proportion of observations in the negative class can be multiplied by the inverse. A proof is given by <a href="http://www.cs.iastate.edu/~honavar/elkan.pdf">Elkan (2001)</a>.</p>
<p>In most cases, the original threshold is <span class="math inline">\(t_0 = 0.5\)</span> and thus the second factor vanishes. If additionally the target threshold <span class="math inline">\(t\)</span> equals the theoretical threshold <span class="math inline">\(t^*\)</span> the proportion of observations in the positive class has to be multiplied by <span class="math display">\[\frac{1-t^*}{t^*} = \frac{c(-1,+1) - c(+1,+1)}{c(+1,-1) - c(-1,-1)}.\]</span></p>
<p>For the <a href="&amp;caret:GermanCredit">credit example</a> the theoretical threshold corresponds to a weight of 5 for the positive class.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Weight for positive class corresponding to theoretical treshold
w =<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span>th)/th
w</code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>A unified and convenient way to assign class weights to a <a href="&amp;makeLearner">Learner</a> (and tune them) is provided by function [&amp;makeWeightedClassesWrapper]. The class weights are specified using argument <code>wcw.weight</code>. For learners that support observation weights a suitable weight vector is then generated internally during training or resampling. If the learner can deal with class weights, the weights are basically passed on to the appropriate learner parameter. The advantage of using the wrapper in this case is the unified way to specify the class weights.</p>
<p>Below is an example using learner <code>"classif.multinom"</code> (<a href="&amp;nnet::multinom">multinom</a> from package [%nnet]) which accepts observation weights. For binary classification problems it is sufficient to specify the weight <code>w</code> for the positive class. The negative class then automatically receives weight 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Weighted learner
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeWeightedClassesWrapper.html">makeWeightedClassesWrapper</a></span>(lrn, <span class="dt">wcw.weight =</span> w)
lrn</code></pre></div>
<pre><code>## Learner weightedclasses.classif.multinom from package nnet
## Type: classif
## Name: ; Short name: 
## Class: WeightedClassesWrapper
## Properties: twoclass,multiclass,numerics,factors,prob
## Predict-Type: response
## Hyperparameters: trace=FALSE,wcw.weight=5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r =<span class="st"> </span><span class="kw"><a href="../../reference/resample.html">resample</a></span>(lrn, credit.task, rin, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>## Resample Result
## Task: GermanCredit
## Learner: weightedclasses.classif.multinom
## Aggr perf: credit.costs.test.mean=0.5528972,mmce.test.mean=0.3529727
## Runtime: 0.409364</code></pre>
<p>For classification methods like <code>"classif.ksvm"</code> (the support vector machine <a href="&amp;kernlab::ksvm">ksvm</a> in package [%kernlab]) that support class weights you can pass them directly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.ksvm"</span>, <span class="dt">class.weights =</span> <span class="kw">c</span>(<span class="dt">Bad =</span> w, <span class="dt">Good =</span> <span class="dv">1</span>))</code></pre></div>
<p>Or, more conveniently, you can again use [&amp;makeWeightedClassesWrapper].</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeWeightedClassesWrapper.html">makeWeightedClassesWrapper</a></span>(<span class="st">"classif.ksvm"</span>, <span class="dt">wcw.weight =</span> w)
r =<span class="st"> </span><span class="kw"><a href="../../reference/resample.html">resample</a></span>(lrn, credit.task, rin, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>## Resample Result
## Task: GermanCredit
## Learner: weightedclasses.classif.ksvm
## Aggr perf: credit.costs.test.mean=0.6409314,mmce.test.mean=0.3489867
## Runtime: 1.82578</code></pre>
<p>Just like the theoretical threshold, the theoretical weights may not always be suitable, therefore you can tune the weight for the positive class as shown in the following example. Calculating the theoretical weight beforehand may help to narrow down the search interval.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeWeightedClassesWrapper.html">makeWeightedClassesWrapper</a></span>(lrn)
ps =<span class="st"> </span><span class="kw">makeParamSet</span>(<span class="kw">makeDiscreteParam</span>(<span class="st">"wcw.weight"</span>, <span class="kw">seq</span>(<span class="dv">4</span>, <span class="dv">12</span>, <span class="fl">0.5</span>)))
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span>()
tune.res =<span class="st"> </span><span class="kw"><a href="../../reference/tuneParams.html">tuneParams</a></span>(lrn, credit.task, <span class="dt">resampling =</span> rin, <span class="dt">par.set =</span> ps,
  <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce), <span class="dt">control =</span> ctrl, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
tune.res</code></pre></div>
<pre><code>## Tune result:
## Op. pars: wcw.weight=8
## credit.costs.test.mean=0.5089161,mmce.test.mean=0.3929798</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">as.data.frame</span>(tune.res$opt.path)[<span class="dv">1</span>:<span class="dv">3</span>]</code></pre></div>
<pre><code>##    wcw.weight credit.costs.test.mean mmce.test.mean
## 1           4              0.5769182      0.3369777
## 2         4.5              0.5679032      0.3439787
## 3           5              0.5528972      0.3529727
## 4         5.5              0.5448742      0.3609658
## 5           6              0.5378912      0.3699748
## 6         6.5              0.5128991      0.3729748
## 7           7              0.5178951      0.3819748
## 8         7.5              0.5109121      0.3869798
## 9           8              0.5089161      0.3929798
## 10        8.5              0.5199091      0.4039728
## 11          9              0.5269101      0.4109738
## 12        9.5              0.5369022      0.4249699
## 13         10              0.5439062      0.4319739
## 14       10.5              0.5419132      0.4339729
## 15         11              0.5329461      0.4369819
## 16       11.5              0.5309591      0.4389869
## 17         12              0.5379601      0.4459879</code></pre>
</div>
<div id="ii--over--and-undersampling" class="section level5">
<h5 class="hasAnchor">
<a href="#ii--over--and-undersampling" class="anchor"></a>ii. Over- and undersampling</h5>
<p>If the <a href="&amp;makeLearner">Learner</a> supports neither observation nor class weights the proportions of the classes in the training data can be changed by over- or undersampling.</p>
<p>In the <a href="&amp;caret::GermanCredit">GermanCredit data set</a> the positive class Bad should receive a theoretical weight of <code>w = (1 - th)/th = 5</code>. This can be achieved by oversampling class Bad with a <code>rate</code> of 5 or by undersampling class Good with a <code>rate</code> of 1/5 (using functions [&amp;oversample] or <a href="&amp;oversample">undersample</a>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">credit.task.over =<span class="st"> </span><span class="kw"><a href="../../reference/oversample.html">oversample</a></span>(credit.task, <span class="dt">rate =</span> w, <span class="dt">cl =</span> <span class="st">"Bad"</span>)
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, credit.task.over)
pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">task =</span> credit.task)
<span class="kw"><a href="../../reference/performance.html">performance</a></span>(pred, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce))</code></pre></div>
<pre><code>## credit.costs         mmce 
##        0.433        0.321</code></pre>
<p>Note that in the above example the learner was trained on the oversampled task <code>credit.task.over</code>. In order to get the training performance on the original task predictions were calculated for <code>credit.task</code>.</p>
<p>We usually prefer resampled performance values, but simply calling [&amp;resample] on the oversampled task does not work since predictions have to be based on the original task. The solution is to create a wrapped <a href="&amp;makeLearner">Learner</a> via function <a href="&amp;makeUndersampleWrapper">makeOversampleWrapper</a>. Internally, [&amp;oversample] is called before training, but predictions are done on the original data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeUndersampleWrapper.html">makeOversampleWrapper</a></span>(lrn, <span class="dt">osw.rate =</span> w, <span class="dt">osw.cl =</span> <span class="st">"Bad"</span>)
lrn</code></pre></div>
<pre><code>## Learner classif.multinom.oversampled from package mlr,nnet
## Type: classif
## Name: ; Short name: 
## Class: OversampleWrapper
## Properties: numerics,factors,weights,prob,twoclass,multiclass
## Predict-Type: response
## Hyperparameters: trace=FALSE,osw.rate=5,osw.cl=Bad</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r =<span class="st"> </span><span class="kw"><a href="../../reference/resample.html">resample</a></span>(lrn, credit.task, rin, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>## Resample Result
## Task: GermanCredit
## Learner: classif.multinom.oversampled
## Aggr perf: credit.costs.test.mean=0.5859183,mmce.test.mean=0.3579777
## Runtime: 0.637533</code></pre>
<p>Of course, we can also tune the oversampling rate. For this purpose we again have to create an <a href="&amp;makeUndersampleWrapper">OversampleWrapper</a>. Optimal values for parameter <code>osw.rate</code> can be obtained using function [&amp;tuneParams].</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeUndersampleWrapper.html">makeOversampleWrapper</a></span>(lrn, <span class="dt">osw.cl =</span> <span class="st">"Bad"</span>)
ps =<span class="st"> </span><span class="kw">makeParamSet</span>(<span class="kw">makeDiscreteParam</span>(<span class="st">"osw.rate"</span>, <span class="kw">seq</span>(<span class="dv">3</span>, <span class="dv">7</span>, <span class="fl">0.25</span>)))
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/makeTuneControlGrid.html">makeTuneControlGrid</a></span>()
tune.res =<span class="st"> </span><span class="kw"><a href="../../reference/tuneParams.html">tuneParams</a></span>(lrn, credit.task, rin, <span class="dt">par.set =</span> ps, <span class="dt">measures =</span> <span class="kw">list</span>(credit.costs, mmce),
  <span class="dt">control =</span> ctrl, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
tune.res</code></pre></div>
<pre><code>## Tune result:
## Op. pars: osw.rate=6.25
## credit.costs.test.mean=0.5288642,mmce.test.mean=0.3649638</code></pre>
</div>
</div>
</div>
<div id="multi-class-problems" class="section level3">
<h3 class="hasAnchor">
<a href="#multi-class-problems" class="anchor"></a>Multi-class problems</h3>
<p>We consider the <a href="&amp;mlbench::mlbench.waveform">waveform</a> data set from package [%mlbench] and add an artificial cost matrix:</p>
<table class="table"><tbody>
<tr class="odd">
<td align="left">true/pred.</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="center">0</td>
<td align="center">30</td>
<td align="center">80</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="center">5</td>
<td align="center">0</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="center">10</td>
<td align="center">8</td>
<td align="center">0</td>
</tr>
</tbody></table>
<p>We start by creating the [&amp;Task], the cost matrix and the corresponding performance measure.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Task
df =<span class="st"> </span>mlbench::<span class="kw">mlbench.waveform</span>(<span class="dv">500</span>)
wf.task =<span class="st"> </span><span class="kw"><a href="../../reference/Task.html">makeClassifTask</a></span>(<span class="dt">id =</span> <span class="st">"waveform"</span>, <span class="dt">data =</span> <span class="kw">as.data.frame</span>(df), <span class="dt">target =</span> <span class="st">"classes"</span>)

## Cost matrix
costs =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">30</span>, <span class="dv">0</span>, <span class="dv">8</span>, <span class="dv">80</span>, <span class="dv">4</span>, <span class="dv">0</span>), <span class="dv">3</span>)
<span class="kw">colnames</span>(costs) =<span class="st"> </span><span class="kw">rownames</span>(costs) =<span class="st"> </span><span class="kw"><a href="../../reference/getTaskClassLevels.html">getTaskClassLevels</a></span>(wf.task)

## Performance measure
wf.costs =<span class="st"> </span><span class="kw"><a href="../../reference/makeCostMeasure.html">makeCostMeasure</a></span>(<span class="dt">id =</span> <span class="st">"wf.costs"</span>, <span class="dt">name =</span> <span class="st">"Waveform costs"</span>, <span class="dt">costs =</span> costs,
  <span class="dt">best =</span> <span class="dv">0</span>, <span class="dt">worst =</span> <span class="dv">10</span>)</code></pre></div>
<p>In the multi-class case, both, <em>thresholding</em> and <em>rebalancing</em> correspond to cost matrices of a certain structure where <span class="math inline">\(c(k,l) = c(l)\)</span> for <span class="math inline">\(k\)</span>, <span class="math inline">\(l = 1, \ldots, K\)</span>, <span class="math inline">\(k \neq l\)</span>. This condition means that the cost of misclassifying an observation is independent of the predicted class label (see <a href="http://homes.cs.washington.edu/~pedrod/papers/kdd99.pdf">Domingos, 1999</a>). Given a cost matrix of this type, theoretical thresholds and weights can be derived in a similar manner as in the binary case. Obviously, the cost matrix given above does not have this special structure.</p>
<div id="thresholding-1" class="section level4">
<h4 class="hasAnchor">
<a href="#thresholding-1" class="anchor"></a>1. Thresholding</h4>
<p>Given a vector of positive threshold values as long as the number of classes <span class="math inline">\(K\)</span>, the predicted probabilities for all classes are adjusted by dividing them by the corresponding threshold value. Then the class with the highest adjusted probability is predicted. This way, as in the binary case, classes with a low threshold are preferred to classes with a larger threshold.</p>
<p>Again this can be done by function [&amp;setThreshold] as shown in the following example (or alternatively by the <code>predict.threshold</code> option of [&amp;makeLearner]). Note that the threshold vector needs to have names that correspond to the class labels.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.rpart"</span>, <span class="dt">predict.type =</span> <span class="st">"prob"</span>)
rin =<span class="st"> </span><span class="kw"><a href="../../reference/makeResampleInstance.html">makeResampleInstance</a></span>(<span class="st">"CV"</span>, <span class="dt">iters =</span> <span class="dv">3</span>, <span class="dt">task =</span> wf.task)
r =<span class="st"> </span><span class="kw"><a href="../../reference/resample.html">resample</a></span>(lrn, wf.task, rin, <span class="dt">measures =</span> <span class="kw">list</span>(wf.costs, mmce), <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
r</code></pre></div>
<pre><code>## Resample Result
## Task: waveform
## Learner: classif.rpart
## Aggr perf: wf.costs.test.mean=6.6507707,mmce.test.mean=0.2640743
## Runtime: 0.0789115</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Calculate thresholds as 1/(average costs of true classes)
th =<span class="st"> </span><span class="dv">2</span>/<span class="kw">rowSums</span>(costs)
<span class="kw">names</span>(th) =<span class="st"> </span><span class="kw"><a href="../../reference/getTaskClassLevels.html">getTaskClassLevels</a></span>(wf.task)
th</code></pre></div>
<pre><code>##          1          2          3 
## 0.01818182 0.22222222 0.11111111</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred.th =<span class="st"> </span><span class="kw"><a href="../../reference/setThreshold.html">setThreshold</a></span>(r$pred, <span class="dt">threshold =</span> th)
<span class="kw"><a href="../../reference/performance.html">performance</a></span>(pred.th, <span class="dt">measures =</span> <span class="kw">list</span>(wf.costs, mmce))</code></pre></div>
<pre><code>##  wf.costs      mmce 
## 4.6773802 0.3598706</code></pre>
<p>The threshold vector <code>th</code> in the above example is chosen according to the average costs of the true classes 55, 4.5 and 9. More exactly, <code>th</code> corresponds to an artificial cost matrix of the structure mentioned above with off-diagonal elements <span class="math inline">\(c(2,1) = c(3,1) = 55\)</span>, <span class="math inline">\(c(1,2) = c(3,2) = 4.5\)</span> and <span class="math inline">\(c(1,3) = c(2,3) = 9\)</span>. This threshold vector may be not optimal but leads to smaller total costs on the data set than the default.</p>
<div id="ii--empirical-thresholding-1" class="section level5">
<h5 class="hasAnchor">
<a href="#ii--empirical-thresholding-1" class="anchor"></a>ii. Empirical thresholding</h5>
<p>As in the binary case it is possible to tune the threshold vector using function [&amp;tuneThreshold]. Since the scaling of the threshold vector does not change the predicted class labels [&amp;tuneThreshold] returns threshold values that lie in [0,1] and sum to unity.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tune.res =<span class="st"> </span><span class="kw"><a href="../../reference/tuneThreshold.html">tuneThreshold</a></span>(<span class="dt">pred =</span> r$pred, <span class="dt">measure =</span> wf.costs)
tune.res</code></pre></div>
<pre><code>## $th
##          1          2          3 
## 0.07102988 0.48079388 0.44817624 
## 
## $perf
## [1] 4.302227</code></pre>
<p>For comparison we show the standardized version of the theoretically motivated threshold vector chosen above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">th/<span class="kw">sum</span>(th)</code></pre></div>
<pre><code>##          1          2          3 
## 0.05172414 0.63218391 0.31609195</code></pre>
</div>
</div>
<div id="rebalancing-1" class="section level4">
<h4 class="hasAnchor">
<a href="#rebalancing-1" class="anchor"></a>2. Rebalancing</h4>
<div id="i--weighting-1" class="section level5">
<h5 class="hasAnchor">
<a href="#i--weighting-1" class="anchor"></a>i. Weighting</h5>
<p>In the multi-class case you have to pass a vector of weights as long as the number of classes <span class="math inline">\(K\)</span> to function [&amp;makeWeightedClassesWrapper]. The weight vector can be tuned using function [&amp;tuneParams].</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeWeightedClassesWrapper.html">makeWeightedClassesWrapper</a></span>(lrn)

ps =<span class="st"> </span><span class="kw">makeParamSet</span>(<span class="kw">makeNumericVectorParam</span>(<span class="st">"wcw.weight"</span>, <span class="dt">len =</span> <span class="dv">3</span>, <span class="dt">lower =</span> <span class="dv">0</span>, <span class="dt">upper =</span> <span class="dv">1</span>))
ctrl =<span class="st"> </span><span class="kw"><a href="../../reference/makeTuneControlRandom.html">makeTuneControlRandom</a></span>()

tune.res =<span class="st"> </span><span class="kw"><a href="../../reference/tuneParams.html">tuneParams</a></span>(lrn, wf.task, <span class="dt">resampling =</span> rin, <span class="dt">par.set =</span> ps,
  <span class="dt">measures =</span> <span class="kw">list</span>(wf.costs, mmce), <span class="dt">control =</span> ctrl, <span class="dt">show.info =</span> <span class="ot">FALSE</span>)
tune.res</code></pre></div>
<pre><code>## Tune result:
## Op. pars: wcw.weight=0.879,0.109,...
## wf.costs.test.mean=2.4365486,mmce.test.mean=0.1720294</code></pre>
</div>
</div>
</div>
</div>
<div id="example-dependent-misclassification-costs" class="section level2">
<h2 class="hasAnchor">
<a href="#example-dependent-misclassification-costs" class="anchor"></a>Example-dependent misclassification costs</h2>
<p>In case of example-dependent costs we have to create a special [&amp;Task] via function [&amp;makeCostSensTask]. For this purpose the feature values <span class="math inline">\(x\)</span> and an <span class="math inline">\(n \times K\)</span> <code>cost</code> matrix that contains the cost vectors for all <span class="math inline">\(n\)</span> examples in the data set are required.</p>
<p>We use the <a href="&amp;datasets::iris">iris</a> data and generate an artificial cost matrix (see <a href="http://dx.doi.org/10.1145/1102351.1102358">Beygelzimer et al., 2005</a>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df =<span class="st"> </span>iris
cost =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">runif</span>(<span class="dv">150</span> *<span class="st"> </span><span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2000</span>), <span class="dv">150</span>) *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">diag</span>(<span class="dv">3</span>))[df$Species,] +<span class="st"> </span><span class="kw">runif</span>(<span class="dv">150</span>, <span class="dv">0</span>, <span class="dv">10</span>)
<span class="kw">colnames</span>(cost) =<span class="st"> </span><span class="kw">levels</span>(iris$Species)
<span class="kw">rownames</span>(cost) =<span class="st"> </span><span class="kw">rownames</span>(iris)
df$Species =<span class="st"> </span><span class="ot">NULL</span>

costsens.task =<span class="st"> </span><span class="kw"><a href="../../reference/Task.html">makeCostSensTask</a></span>(<span class="dt">id =</span> <span class="st">"iris"</span>, <span class="dt">data =</span> df, <span class="dt">cost =</span> cost)
costsens.task</code></pre></div>
<pre><code>## Supervised task: iris
## Type: costsens
## Observations: 150
## Features:
##    numerics     factors     ordered functionals 
##           4           0           0           0 
## Missings: FALSE
## Has blocking: FALSE
## Is spatial: FALSE
## Classes: 3
## setosa, versicolor, virginica</code></pre>
<p>[%mlr] provides several <a href="wrapper.md">wrappers</a> to turn regular classification or regression methods into <a href="&amp;makeLearner">Learner</a>s that can deal with example-dependent costs.</p>
<ul>
<li>[&amp;makeCostSensClassifWrapper] (wraps a classification <a href="&amp;makeLearner">Learner</a>): This is a naive approach where the costs are coerced into class labels by choosing the class label with minimum cost for each example. Then a regular classification method is used.</li>
<li>[&amp;makeCostSensRegrWrapper] (wraps a regression <a href="&amp;makeLearner">Learner</a>): An individual regression model is fitted for the costs of each class. In the prediction step first the costs are predicted for all classes and then the class with the lowest predicted costs is selected.</li>
<li>[&amp;makeCostSensWeightedPairsWrapper] (wraps a classification <a href="&amp;makeLearner">Learner</a>): This is also known as <em>cost-sensitive one-vs-one</em> (CS-OVO) and the most sophisticated of the currently supported methods. For each pair of classes, a binary classifier is fitted. For each observation the class label is defined as the element of the pair with minimal costs. During fitting, the observations are weighted with the absolute difference in costs. Prediction is performed by simple voting.</li>
</ul>
<p>In the following example we use the third method. We create the wrapped <a href="&amp;makeLearner">Learner</a> and train it on the <a href="&amp;Task">CostSensTask</a> defined above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeLearner.html">makeLearner</a></span>(<span class="st">"classif.multinom"</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
lrn =<span class="st"> </span><span class="kw"><a href="../../reference/makeCostSensWeightedPairsWrapper.html">makeCostSensWeightedPairsWrapper</a></span>(lrn)
lrn</code></pre></div>
<pre><code>## Learner costsens.classif.multinom from package nnet
## Type: costsens
## Name: ; Short name: 
## Class: CostSensWeightedPairsWrapper
## Properties: twoclass,multiclass,numerics,factors
## Predict-Type: response
## Hyperparameters: trace=FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod =<span class="st"> </span><span class="kw"><a href="../../reference/train.html">train</a></span>(lrn, costsens.task)
mod</code></pre></div>
<pre><code>## Model for learner.id=costsens.classif.multinom; learner.class=CostSensWeightedPairsWrapper
## Trained on: task.id = iris; obs = 150; features = 4
## Hyperparameters: trace=FALSE</code></pre>
<p>The models corresponding to the individual pairs can be accessed by function [&amp;getLearnerModel].</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../reference/getLearnerModel.html">getLearnerModel</a></span>(mod)</code></pre></div>
<pre><code>## [[1]]
## Model for learner.id=classif.multinom; learner.class=classif.multinom
## Trained on: task.id = feats; obs = 150; features = 4
## Hyperparameters: trace=FALSE
## 
## [[2]]
## Model for learner.id=classif.multinom; learner.class=classif.multinom
## Trained on: task.id = feats; obs = 150; features = 4
## Hyperparameters: trace=FALSE
## 
## [[3]]
## Model for learner.id=classif.multinom; learner.class=classif.multinom
## Trained on: task.id = feats; obs = 150; features = 4
## Hyperparameters: trace=FALSE</code></pre>
<p>[%mlr] provides some performance measures for example-specific cost-sensitive classification. In the following example we calculate the mean costs of the predicted class labels (<a href="measures.md">meancosts</a>) and the misclassification penalty (<a href="measures.md">mcp</a>). The latter measure is the average difference between the costs caused by the predicted class labels, i.e., <a href="measures.md">meancosts</a>, and the costs resulting from choosing the class with lowest cost for each observation. In order to compute these measures the costs for the test observations are required and therefore the [&amp;Task] has to be passed to [&amp;performance].</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred =<span class="st"> </span><span class="kw">predict</span>(mod, <span class="dt">task =</span> costsens.task)
pred</code></pre></div>
<pre><code>## Prediction: 150 observations
## predict.type: response
## threshold: 
## time: 0.13
##   id response
## 1  1   setosa
## 2  2   setosa
## 3  3   setosa
## 4  4   setosa
## 5  5   setosa
## 6  6   setosa
## ... (#rows: 150, #cols: 2)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../../reference/performance.html">performance</a></span>(pred, <span class="dt">measures =</span> <span class="kw">list</span>(meancosts, mcp), <span class="dt">task =</span> costsens.task)</code></pre></div>
<pre><code>## meancosts       mcp 
##  163.9925  158.8895</code></pre>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#class-dependent-misclassification-costs">Class-dependent misclassification costs</a></li>
      <li><a href="#example-dependent-misclassification-costs">Example-dependent misclassification costs</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Bernd Bischl, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Zachary Jones, Giuseppe Casalicchio, Mason Gallo.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
