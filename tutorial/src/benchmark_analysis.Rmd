# Benchmark Analysis

This section is concerned with the statistical evaluation of benchmark
experiments and interpreting the results in a proper way. Common questions
are (after selecting a performance measure):

* Is classifier A significantly better than classifier B?
* Given a group of classifiers, can we identify relations where ...

We won't go into the theoretical details here, but link to some helpful papers:

<!--- * [[Salzberg1997]](../literature.md#[Salzberg1997]) is a good introduction to the topic.

* [[Dietterich1998]](../literature.md#[Dietterich1998]) FIXME

* [[Hornik1998]](../literature.md#[Hornik1998]) tries to establish a general, statistically valid framework of the theory. Also contains a good overview and critique of previous methods and tests.
-->

* The [benchmarking group](http://www.stat.uni-muenchen.de/institut/ag/leisch/work/benchmarking.html) at LMU.

* [Exploratory and Inferential Analysis of Benchmark Experiments](http://epub.ub.uni-muenchen.de/4134/).
  Expands on the above paper, mostly with regard to practical issues.

* The [benchmark](http://r-forge.r-project.org/projects/benchmark/) package by Eugster et.al.

