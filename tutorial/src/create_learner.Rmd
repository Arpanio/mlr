Integrating another learner
===========================

In order to create a new learner in **mlr**, interface code to the R function
must be written. This can be done by either inheriting from
``rlearner.classif``, ``rlearner.regr``, ``rlearner.surv``, rlearner.costsens``,
or ``rlearner.cluster``. Below, an example of how the
Linear Discriminant Analysis from ``MASS`` package has been integrated into
the classification learner ``classif.lda`` in **mlr** is shown.

Initialization
--------------

For initialization, all the information you need is the name of the learner, its
package, the parameter set, and the set of properties of your learner.

First, name your learner. The naming conventions 
in **mlr** are ``classif.<R_method_name>`` for classification, ``regr.<R_method_name>`` for 
regression, ``surv.<R_method_name>`` for survival analysis,
``costsens.<R_method_name>`` for cost sensitive learning, and
``cluster.<R_method_name>`` for clustering.
Second, use \man2[makeDiscreteLearnerParam][LearnerParam] and
\man2[makeNumericLearnerParam][LearnerParam] to incorporate 
the complete description of the parameters. Include all possible values for
discrete parameters and
lower and upper bounds for numeric parameters. Add information for the properties (see also 
the section about [Learners](learner.md)). Which types of predictors that are
supported (numerics, factors)? 
Are case weights supported? Can the method deal with missing values in the
features and deal with 
NAs in a meaningful way (not ``na.omit``)? Are oneclass, twoclass, multiclass
problems supported? Can the 
learner predict posterior probabilities? In the regression case, you do not need to take care of the 
latter properties. For the other types of learners, not all of these properties
are relevant.

In the following example, you see the R code for Linear Discriminant Analysis. The name is 
``"classif.lda"`` from the package ``MASS``. LDA has one discrete parameter, ``method``, and two 
continuous ones, ``nu`` and ``tol``. It supports classification problems with two or more classes and 
can deal with numeric and factor explanatory variables. It can predict posterior probabilities.

```{r}
makeRLearner.classif.lda = function() {
  makeRLearnerClassif(
    cl = "classif.lda",
    package = "MASS",
    par.set = makeParamSet(
  	  makeDiscreteLearnerParam(id="method", default="moment", values=c("moment", "mle", "mve", "t")),
  		makeNumericLearnerParam(id="nu", lower=2, requires=expression(method=="t")),
      makeNumericLearnerParam(id="tol", default=1.0e-4, lower=0)
    ), 
    twoclass = TRUE, 
    multiclass = TRUE, 
    numerics = TRUE, 
    factors = TRUE, 
    prob = TRUE
  )
}
```

Creating the training function of the learner
---------------------------------------------

This must fit a model on the data of the task ``.task`` with regard to the subset defined in the 
integer vector ``.subset`` and the parameters passed in the ``...`` arguments. It must return the 
fitted model, no special data type is assumed for this. Further information can
be found in the documentation of \man[getTaskData].

In the example, replace ``lda`` with the name of the training function of your method. Pass all 
required arguments to the training function. The data can be extracted from the task via the 
\man[getTaskData] function. Pass further arguments like case weights via
``.weights`` to the training method.

```{r}
trainLearner.classif.lda = function(.learner, .task, .subset, .weights,  ...) {
  f = getTaskFormula(.task)
  lda(f, data=getTaskData(.task, .subset), ...)
}
```

Creating the prediction method 
------------------------------

This must predict for the new observations in the `data.frame` ``.newdata`` with
the wrapped model ``.model.`` 
Simply access the real fitted model by ``.model$learner.model``. For regression you have to return a 
numeric vector of predicted response values. For classification you have to return a factor of predicted
classes if ``.learner$predict.type`` is ``"response"``, or you have return a matrix of predicted probabilities if
``.learner$predict.type`` is ``"prob"``. In the latter case the matrix must have the same number of columns as there
are classes in the task and the columns have to be named by the class names. For
clustering, you have to return a numeric vector with the IDs of the clusters
that the respective datum has been assigned to.

```{r}
predictLearner.classif.lda = function(.learner, .model, .newdata, ...) {
	p = predict(.model$learner.model, newdata=.newdata, ...)
	if(.learner$predict.type == "response")
		return(p$class)
	else
		return(p$posterior)
}
``` 



