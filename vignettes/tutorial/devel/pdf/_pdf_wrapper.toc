\contentsline {section}{\numberline {1}Machine Learning in R: mlr Tutorial}{6}{section.1}
\contentsline {subsection}{\numberline {1.1}Quick start}{7}{subsection.1.1}
\contentsline {section}{\numberline {2}Basics}{7}{section.2}
\contentsline {subsection}{\numberline {2.1}Task types and creation}{7}{subsection.2.1}
\contentsline {subsubsection}{\numberline {2.1.1}Regression}{8}{subsubsection.2.1.1}
\contentsline {subsubsection}{\numberline {2.1.2}Classification}{8}{subsubsection.2.1.2}
\contentsline {subsubsection}{\numberline {2.1.3}Survival analysis}{9}{subsubsection.2.1.3}
\contentsline {subsubsection}{\numberline {2.1.4}Multilabel classification}{9}{subsubsection.2.1.4}
\contentsline {subsubsection}{\numberline {2.1.5}Cluster analysis}{10}{subsubsection.2.1.5}
\contentsline {subsubsection}{\numberline {2.1.6}Cost-sensitive classification}{10}{subsubsection.2.1.6}
\contentsline {subsection}{\numberline {2.2}Further settings}{11}{subsection.2.2}
\contentsline {subsection}{\numberline {2.3}Accessing a learning task}{11}{subsection.2.3}
\contentsline {subsection}{\numberline {2.4}Modifying a learning task}{14}{subsection.2.4}
\contentsline {subsection}{\numberline {2.5}Example tasks and convenience functions}{15}{subsection.2.5}
\contentsline {subsection}{\numberline {2.6}Constructing a learner}{15}{subsection.2.6}
\contentsline {subsection}{\numberline {2.7}Accessing a learner}{16}{subsection.2.7}
\contentsline {subsection}{\numberline {2.8}Modifying a learner}{18}{subsection.2.8}
\contentsline {subsection}{\numberline {2.9}Listing learners}{19}{subsection.2.9}
\contentsline {subsection}{\numberline {2.10}Accessing the prediction}{21}{subsection.2.10}
\contentsline {subsubsection}{\numberline {2.10.1}Regression: Extracting standard errors}{22}{subsubsection.2.10.1}
\contentsline {subsubsection}{\numberline {2.10.2}Classification and clustering: Extracting probabilities}{23}{subsubsection.2.10.2}
\contentsline {subsubsection}{\numberline {2.10.3}Classification: Confusion matrix}{24}{subsubsection.2.10.3}
\contentsline {subsection}{\numberline {2.11}Classification: Adjusting the decision threshold}{26}{subsection.2.11}
\contentsline {subsection}{\numberline {2.12}Visualizing the prediction}{27}{subsection.2.12}
\contentsline {subsection}{\numberline {2.13}Available performance measures}{30}{subsection.2.13}
\contentsline {subsection}{\numberline {2.14}Listing measures}{31}{subsection.2.14}
\contentsline {subsection}{\numberline {2.15}Calculate performance measures}{32}{subsection.2.15}
\contentsline {subsubsection}{\numberline {2.15.1}Requirements of performance measures}{32}{subsubsection.2.15.1}
\contentsline {subsection}{\numberline {2.16}Access a performance measure}{33}{subsection.2.16}
\contentsline {subsection}{\numberline {2.17}Binary classification}{33}{subsection.2.17}
\contentsline {subsubsection}{\numberline {2.17.1}Plot performance versus threshold}{33}{subsubsection.2.17.1}
\contentsline {subsubsection}{\numberline {2.17.2}ROC measures}{34}{subsubsection.2.17.2}
\contentsline {subsection}{\numberline {2.18}Defining the resampling strategy}{35}{subsection.2.18}
\contentsline {subsection}{\numberline {2.19}Performing the resampling}{37}{subsection.2.19}
\contentsline {subsection}{\numberline {2.20}Accessing resample results}{39}{subsection.2.20}
\contentsline {subsubsection}{\numberline {2.20.1}Predictions}{39}{subsubsection.2.20.1}
\contentsline {subsubsection}{\numberline {2.20.2}Learner models}{41}{subsubsection.2.20.2}
\contentsline {subsubsection}{\numberline {2.20.3}The extract option}{42}{subsubsection.2.20.3}
\contentsline {subsection}{\numberline {2.21}Stratification and blocking}{44}{subsection.2.21}
\contentsline {subsubsection}{\numberline {2.21.1}Stratification with respect to the target variable(s)}{44}{subsubsection.2.21.1}
\contentsline {subsubsection}{\numberline {2.21.2}Stratification with respect to explanatory variables}{44}{subsubsection.2.21.2}
\contentsline {subsubsection}{\numberline {2.21.3}Blocking}{45}{subsubsection.2.21.3}
\contentsline {subsection}{\numberline {2.22}Resample descriptions and resample instances}{45}{subsection.2.22}
\contentsline {subsection}{\numberline {2.23}Aggregating performance values}{48}{subsection.2.23}
\contentsline {subsubsection}{\numberline {2.23.1}Example: One measure with different aggregations}{48}{subsubsection.2.23.1}
\contentsline {subsubsection}{\numberline {2.23.2}Example: Calculating the training error}{49}{subsubsection.2.23.2}
\contentsline {subsubsection}{\numberline {2.23.3}Example: Bootstrap}{50}{subsubsection.2.23.3}
\contentsline {subsection}{\numberline {2.24}Convenience functions}{50}{subsection.2.24}
\contentsline {subsection}{\numberline {2.25}Specifying the search space}{52}{subsection.2.25}
\contentsline {subsection}{\numberline {2.26}Specifying the optimization algorithm}{53}{subsection.2.26}
\contentsline {subsection}{\numberline {2.27}Performing the tuning}{53}{subsection.2.27}
\contentsline {subsection}{\numberline {2.28}Accessing the tuning result}{55}{subsection.2.28}
\contentsline {subsection}{\numberline {2.29}Investigating hyperparameter tuning effects}{56}{subsection.2.29}
\contentsline {subsection}{\numberline {2.30}Further comments}{58}{subsection.2.30}
\contentsline {subsection}{\numberline {2.31}Conducting benchmark experiments}{59}{subsection.2.31}
\contentsline {subsubsection}{\numberline {2.31.1}Making experiments reproducible}{60}{subsubsection.2.31.1}
\contentsline {subsection}{\numberline {2.32}Accessing benchmark results}{60}{subsection.2.32}
\contentsline {subsubsection}{\numberline {2.32.1}Learner performances}{60}{subsubsection.2.32.1}
\contentsline {subsubsection}{\numberline {2.32.2}Predictions}{61}{subsubsection.2.32.2}
\contentsline {subsubsection}{\numberline {2.32.3}IDs}{63}{subsubsection.2.32.3}
\contentsline {subsubsection}{\numberline {2.32.4}Fitted models}{63}{subsubsection.2.32.4}
\contentsline {subsubsection}{\numberline {2.32.5}Learners and measures}{64}{subsubsection.2.32.5}
\contentsline {subsection}{\numberline {2.33}Merging benchmark results}{64}{subsection.2.33}
\contentsline {subsection}{\numberline {2.34}Benchmark analysis and visualization}{66}{subsection.2.34}
\contentsline {subsubsection}{\numberline {2.34.1}Example: Comparing lda, rpart and random Forest}{66}{subsubsection.2.34.1}
\contentsline {subsubsection}{\numberline {2.34.2}Integrated plots}{68}{subsubsection.2.34.2}
\contentsline {paragraph}{\numberline {2.34.2.1}Visualizing performances}{68}{paragraph.2.34.2.1}
\contentsline {paragraph}{\numberline {2.34.2.2}Visualizing aggregated performances}{70}{paragraph.2.34.2.2}
\contentsline {paragraph}{\numberline {2.34.2.3}Calculating and visualizing ranks}{71}{paragraph.2.34.2.3}
\contentsline {subsubsection}{\numberline {2.34.3}Comparing learners using hypothesis tests}{74}{subsubsection.2.34.3}
\contentsline {subsubsection}{\numberline {2.34.4}Critical differences diagram}{74}{subsubsection.2.34.4}
\contentsline {subsubsection}{\numberline {2.34.5}Custom plots}{76}{subsubsection.2.34.5}
\contentsline {subsection}{\numberline {2.35}Further comments}{78}{subsection.2.35}
\contentsline {subsection}{\numberline {2.36}Parallelization levels}{79}{subsection.2.36}
\contentsline {subsection}{\numberline {2.37}Custom learners and parallelization}{79}{subsection.2.37}
\contentsline {subsection}{\numberline {2.38}The end}{80}{subsection.2.38}
\contentsline {subsection}{\numberline {2.39}Generation and plotting functions}{80}{subsection.2.39}
\contentsline {subsubsection}{\numberline {2.39.1}Some examples}{80}{subsubsection.2.39.1}
\contentsline {subsubsection}{\numberline {2.39.2}Customizing plots}{81}{subsubsection.2.39.2}
\contentsline {subsection}{\numberline {2.40}Available generation and plotting functions}{86}{subsection.2.40}
\contentsline {section}{\numberline {3}Advanced}{87}{section.3}
\contentsline {subsection}{\numberline {3.1}Example: Reducing the output on the console}{87}{subsection.3.1}
\contentsline {subsection}{\numberline {3.2}Accessing and resetting the configuration}{88}{subsection.3.2}
\contentsline {subsection}{\numberline {3.3}Example: Turning off parameter checking}{89}{subsection.3.3}
\contentsline {subsection}{\numberline {3.4}Example: Handling errors in a learning method}{89}{subsection.3.4}
\contentsline {subsection}{\numberline {3.5}Example: Bagging wrapper}{91}{subsection.3.5}
\contentsline {subsection}{\numberline {3.6}Fusing learners with preprocessing}{94}{subsection.3.6}
\contentsline {subsection}{\numberline {3.7}Preprocessing with makePreprocWrapperCaret}{95}{subsection.3.7}
\contentsline {subsubsection}{\numberline {3.7.1}Joint tuning of preprocessing options and learner parameters}{97}{subsubsection.3.7.1}
\contentsline {subsection}{\numberline {3.8}Writing a custom preprocessing wrapper}{99}{subsection.3.8}
\contentsline {subsubsection}{\numberline {3.8.1}Specifying the train function}{100}{subsubsection.3.8.1}
\contentsline {subsubsection}{\numberline {3.8.2}Specifying the predict function}{100}{subsubsection.3.8.2}
\contentsline {subsubsection}{\numberline {3.8.3}Creating the preprocessing wrapper}{101}{subsubsection.3.8.3}
\contentsline {subsubsection}{\numberline {3.8.4}Joint tuning of preprocessing and learner parameters}{102}{subsubsection.3.8.4}
\contentsline {subsubsection}{\numberline {3.8.5}Preprocessing wrapper functions}{103}{subsubsection.3.8.5}
\contentsline {subsection}{\numberline {3.9}Imputation and reimputation}{105}{subsection.3.9}
\contentsline {subsection}{\numberline {3.10}Fusing a learner with imputation}{108}{subsection.3.10}
\contentsline {subsection}{\numberline {3.11}Changing the type of prediction}{110}{subsection.3.11}
\contentsline {subsection}{\numberline {3.12}Tuning across whole model spaces with ModelMultiplexer}{112}{subsection.3.12}
\contentsline {subsection}{\numberline {3.13}Multi-criteria evaluation and optimization}{113}{subsection.3.13}
\contentsline {subsection}{\numberline {3.14}Filter methods}{115}{subsection.3.14}
\contentsline {subsubsection}{\numberline {3.14.1}Calculating the feature importance}{115}{subsubsection.3.14.1}
\contentsline {subsubsection}{\numberline {3.14.2}Selecting a feature subset}{116}{subsubsection.3.14.2}
\contentsline {subsubsection}{\numberline {3.14.3}Fuse a learner with a filter method}{117}{subsubsection.3.14.3}
\contentsline {subsubsection}{\numberline {3.14.4}Tuning the size of the feature subset}{118}{subsubsection.3.14.4}
\contentsline {subsection}{\numberline {3.15}Wrapper methods}{120}{subsection.3.15}
\contentsline {subsubsection}{\numberline {3.15.1}Select a feature subset}{121}{subsubsection.3.15.1}
\contentsline {subsubsection}{\numberline {3.15.2}Fuse a learner with feature selection}{122}{subsubsection.3.15.2}
\contentsline {subsection}{\numberline {3.16}Tuning}{125}{subsection.3.16}
\contentsline {subsubsection}{\numberline {3.16.1}Accessing the tuning result}{126}{subsubsection.3.16.1}
\contentsline {subsection}{\numberline {3.17}Feature selection}{127}{subsection.3.17}
\contentsline {subsubsection}{\numberline {3.17.1}Wrapper methods}{127}{subsubsection.3.17.1}
\contentsline {paragraph}{\numberline {3.17.1.1}Accessing the selected features}{128}{paragraph.3.17.1.1}
\contentsline {subsubsection}{\numberline {3.17.2}Filter methods with tuning}{129}{subsubsection.3.17.2}
\contentsline {paragraph}{\numberline {3.17.2.1}Accessing the selected features and optimal percentage}{130}{paragraph.3.17.2.1}
\contentsline {subsection}{\numberline {3.18}Benchmark experiments}{131}{subsection.3.18}
\contentsline {subsubsection}{\numberline {3.18.1}Example 1: Two tasks, two learners, tuning}{131}{subsubsection.3.18.1}
\contentsline {subsubsection}{\numberline {3.18.2}Example 2: One task, two learners, feature selection}{134}{subsubsection.3.18.2}
\contentsline {subsubsection}{\numberline {3.18.3}Example 3: One task, two learners, feature filtering with tuning}{136}{subsubsection.3.18.3}
\contentsline {subsubsection}{\numberline {3.18.4}Class-dependent misclassification costs}{137}{subsubsection.3.18.4}
\contentsline {subsubsection}{\numberline {3.18.5}Binary classification problems}{137}{subsubsection.3.18.5}
\contentsline {paragraph}{\numberline {3.18.5.1}1. Thresholding}{138}{paragraph.3.18.5.1}
\contentsline {subparagraph}{\numberline {3.18.5.1.1}i. Theoretical thresholding}{139}{subparagraph.3.18.5.1.1}
\contentsline {subparagraph}{\numberline {3.18.5.1.2}ii. Empirical thresholding}{141}{subparagraph.3.18.5.1.2}
\contentsline {paragraph}{\numberline {3.18.5.2}2. Rebalancing}{142}{paragraph.3.18.5.2}
\contentsline {subparagraph}{\numberline {3.18.5.2.1}i. Weighting}{142}{subparagraph.3.18.5.2.1}
\contentsline {subparagraph}{\numberline {3.18.5.2.2}ii. Over- and undersampling}{144}{subparagraph.3.18.5.2.2}
\contentsline {subsubsection}{\numberline {3.18.6}Multi-class problems}{145}{subsubsection.3.18.6}
\contentsline {paragraph}{\numberline {3.18.6.1}1. Thresholding}{146}{paragraph.3.18.6.1}
\contentsline {subparagraph}{\numberline {3.18.6.1.1}ii. Empirical thresholding}{147}{subparagraph.3.18.6.1.1}
\contentsline {paragraph}{\numberline {3.18.6.2}2. Rebalancing}{147}{paragraph.3.18.6.2}
\contentsline {subparagraph}{\numberline {3.18.6.2.1}i. Weighting}{147}{subparagraph.3.18.6.2.1}
\contentsline {subsection}{\numberline {3.19}Example-dependent misclassification costs}{147}{subsection.3.19}
\contentsline {subsection}{\numberline {3.20}Sampling-based approaches}{150}{subsection.3.20}
\contentsline {subsubsection}{\numberline {3.20.1}(Simple) over- and undersampling}{150}{subsubsection.3.20.1}
\contentsline {subsubsection}{\numberline {3.20.2}Over- and undersampling wrappers}{151}{subsubsection.3.20.2}
\contentsline {subsubsection}{\numberline {3.20.3}Extensions to oversampling}{152}{subsubsection.3.20.3}
\contentsline {paragraph}{\numberline {3.20.3.1}1. SMOTE (Synthetic Minority Oversampling Technique)}{152}{paragraph.3.20.3.1}
\contentsline {paragraph}{\numberline {3.20.3.2}2. Overbagging}{152}{paragraph.3.20.3.2}
\contentsline {subsection}{\numberline {3.21}Cost-based approaches}{153}{subsection.3.21}
\contentsline {subsubsection}{\numberline {3.21.1}Weighted classes wrapper}{154}{subsubsection.3.21.1}
\contentsline {subsection}{\numberline {3.22}Performance plots with plotROCCurves}{155}{subsection.3.22}
\contentsline {subsubsection}{\numberline {3.22.1}Example 1: Single predictions}{155}{subsubsection.3.22.1}
\contentsline {subsubsection}{\numberline {3.22.2}Example 2: Benchmark experiment}{159}{subsubsection.3.22.2}
\contentsline {subsection}{\numberline {3.23}Performance plots with asROCRPrediction}{163}{subsection.3.23}
\contentsline {subsubsection}{\numberline {3.23.1}Example 1: Single predictions (continued)}{164}{subsubsection.3.23.1}
\contentsline {subsubsection}{\numberline {3.23.2}Example 2: Benchmark experiments (continued)}{165}{subsubsection.3.23.2}
\contentsline {subsection}{\numberline {3.24}Viper charts}{168}{subsection.3.24}
\contentsline {subsection}{\numberline {3.25}Creating a task}{168}{subsection.3.25}
\contentsline {subsection}{\numberline {3.26}Constructing a learner}{168}{subsection.3.26}
\contentsline {subsubsection}{\numberline {3.26.1}Algorithm adaptation methods}{169}{subsubsection.3.26.1}
\contentsline {subsubsection}{\numberline {3.26.2}Problem transformation methods}{169}{subsubsection.3.26.2}
\contentsline {paragraph}{\numberline {3.26.2.1}Binary relevance}{170}{paragraph.3.26.2.1}
\contentsline {paragraph}{\numberline {3.26.2.2}Classifier chains}{170}{paragraph.3.26.2.2}
\contentsline {paragraph}{\numberline {3.26.2.3}Nested stacking}{170}{paragraph.3.26.2.3}
\contentsline {paragraph}{\numberline {3.26.2.4}Dependent binary relevance}{170}{paragraph.3.26.2.4}
\contentsline {paragraph}{\numberline {3.26.2.5}Stacking}{170}{paragraph.3.26.2.5}
\contentsline {subsection}{\numberline {3.27}Train}{170}{subsection.3.27}
\contentsline {subsection}{\numberline {3.28}Predict}{170}{subsection.3.28}
\contentsline {subsection}{\numberline {3.29}Performance}{171}{subsection.3.29}
\contentsline {subsection}{\numberline {3.30}Resampling}{172}{subsection.3.30}
\contentsline {subsection}{\numberline {3.31}Binary performance}{172}{subsection.3.31}
\contentsline {subsection}{\numberline {3.32}Plotting the learning curve}{173}{subsection.3.32}
\contentsline {subsection}{\numberline {3.33}Generating partial dependences}{177}{subsection.3.33}
\contentsline {subsection}{\numberline {3.34}Functional ANOVA}{182}{subsection.3.34}
\contentsline {subsection}{\numberline {3.35}Plotting partial dependences}{184}{subsection.3.35}
\contentsline {subsection}{\numberline {3.36}Generating hyperparameter tuning data}{196}{subsection.3.36}
\contentsline {subsection}{\numberline {3.37}Visualizing the effect of a single hyperparameter}{198}{subsection.3.37}
\contentsline {subsection}{\numberline {3.38}Visualizing the effect of 2 hyperparameters}{201}{subsection.3.38}
\contentsline {subsection}{\numberline {3.39}Visualizing the effects of more than 2 hyperparameters}{206}{subsection.3.39}
\contentsline {subsection}{\numberline {3.40}Introduction}{209}{subsection.3.40}
\contentsline {subsection}{\numberline {3.41}How to use spatial partitioning in mlr}{210}{subsection.3.41}
\contentsline {subsection}{\numberline {3.42}Examples}{210}{subsection.3.42}
\contentsline {subsubsection}{\numberline {3.42.1}Spatial Cross-Validation}{210}{subsubsection.3.42.1}
\contentsline {subsubsection}{\numberline {3.42.2}Non-Spatial Cross-Validation}{212}{subsubsection.3.42.2}
\contentsline {subsection}{\numberline {3.43}Notes}{214}{subsection.3.43}
\contentsline {section}{\numberline {4}Extending}{214}{section.4}
\contentsline {subsection}{\numberline {4.1}Classes, constructors, and naming schemes}{214}{subsection.4.1}
\contentsline {subsection}{\numberline {4.2}Classification}{215}{subsection.4.2}
\contentsline {subsubsection}{\numberline {4.2.1}Definition of the learner}{215}{subsubsection.4.2.1}
\contentsline {subsubsection}{\numberline {4.2.2}Creating the training function of the learner}{216}{subsubsection.4.2.2}
\contentsline {subsubsection}{\numberline {4.2.3}Creating the prediction method}{217}{subsubsection.4.2.3}
\contentsline {subsection}{\numberline {4.3}Regression}{217}{subsection.4.3}
\contentsline {subsection}{\numberline {4.4}Survival analysis}{218}{subsection.4.4}
\contentsline {subsection}{\numberline {4.5}Clustering}{219}{subsection.4.5}
\contentsline {subsection}{\numberline {4.6}Multilabel classification}{220}{subsection.4.6}
\contentsline {subsection}{\numberline {4.7}Creating a new method for extracting feature importance values}{221}{subsection.4.7}
\contentsline {subsection}{\numberline {4.8}Creating a new method for extracting out-of-bag predictions}{221}{subsection.4.8}
\contentsline {subsection}{\numberline {4.9}Registering your learner}{222}{subsection.4.9}
\contentsline {subsection}{\numberline {4.10}Further information for developers}{222}{subsection.4.10}
\contentsline {subsection}{\numberline {4.11}Unit testing}{223}{subsection.4.11}
\contentsline {subsection}{\numberline {4.12}Performance measures and aggregation schemes}{225}{subsection.4.12}
\contentsline {subsection}{\numberline {4.13}Constructing a performance measure}{226}{subsection.4.13}
\contentsline {subsection}{\numberline {4.14}Constructing a measure for ordinary misclassification costs}{227}{subsection.4.14}
\contentsline {subsection}{\numberline {4.15}Creating an aggregation scheme}{228}{subsection.4.15}
\contentsline {subsection}{\numberline {4.16}Example: Evaluating the range of measures}{228}{subsection.4.16}
\contentsline {subsection}{\numberline {4.17}Example: Imputation using the mean}{230}{subsection.4.17}
\contentsline {subsection}{\numberline {4.18}Writing your own imputation method}{231}{subsection.4.18}
\contentsline {subsection}{\numberline {4.19}Filter objects}{232}{subsection.4.19}
\contentsline {subsection}{\numberline {4.20}Writing a new filter method}{233}{subsection.4.20}
\contentsline {section}{\numberline {5}Appendix}{236}{section.5}
\contentsline {subsubsection}{\numberline {5.0.1}Classification (84)}{236}{subsubsection.5.0.1}
\contentsline {subsubsection}{\numberline {5.0.2}Regression (61)}{238}{subsubsection.5.0.2}
\contentsline {subsubsection}{\numberline {5.0.3}Survival analysis (12)}{239}{subsubsection.5.0.3}
\contentsline {subsubsection}{\numberline {5.0.4}Cluster analysis (9)}{240}{subsubsection.5.0.4}
\contentsline {subsubsection}{\numberline {5.0.5}Cost-sensitive classification}{240}{subsubsection.5.0.5}
\contentsline {subsubsection}{\numberline {5.0.6}Multilabel classification (3)}{240}{subsubsection.5.0.6}
\contentsline {subsubsection}{\numberline {5.0.7}Classification}{241}{subsubsection.5.0.7}
\contentsline {subsubsection}{\numberline {5.0.8}Regression}{242}{subsubsection.5.0.8}
\contentsline {subsubsection}{\numberline {5.0.9}Survival analysis}{242}{subsubsection.5.0.9}
\contentsline {subsubsection}{\numberline {5.0.10}Cluster analysis}{242}{subsubsection.5.0.10}
\contentsline {subsubsection}{\numberline {5.0.11}Cost-sensitive classification}{243}{subsubsection.5.0.11}
\contentsline {subsubsection}{\numberline {5.0.12}Multilabel classification}{243}{subsubsection.5.0.12}
\contentsline {subsubsection}{\numberline {5.0.13}General performance measures}{243}{subsubsection.5.0.13}
\contentsline {subsection}{\numberline {5.1}Current methods}{243}{subsection.5.1}
\contentsline {subsection}{\numberline {5.2}Deprecated methods}{244}{subsection.5.2}
