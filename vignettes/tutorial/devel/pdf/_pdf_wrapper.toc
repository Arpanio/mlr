\contentsline {section}{\numberline {1}Machine Learning in R: mlr Tutorial}{5}{section.1}
\contentsline {subsection}{\numberline {1.1}Quick start}{5}{subsection.1.1}
\contentsline {section}{\numberline {2}Basics}{6}{section.2}
\contentsline {subsection}{\numberline {2.1}Learning Tasks}{6}{subsection.2.1}
\contentsline {subsubsection}{\numberline {2.1.1}Task types and creation}{6}{subsubsection.2.1.1}
\contentsline {paragraph}{\numberline {2.1.1.1}Regression}{6}{paragraph.2.1.1.1}
\contentsline {paragraph}{\numberline {2.1.1.2}Classification}{7}{paragraph.2.1.1.2}
\contentsline {paragraph}{\numberline {2.1.1.3}Survival analysis}{8}{paragraph.2.1.1.3}
\contentsline {paragraph}{\numberline {2.1.1.4}Multilabel classification}{8}{paragraph.2.1.1.4}
\contentsline {paragraph}{\numberline {2.1.1.5}Cluster analysis}{9}{paragraph.2.1.1.5}
\contentsline {paragraph}{\numberline {2.1.1.6}Cost-sensitive classification}{9}{paragraph.2.1.1.6}
\contentsline {subsubsection}{\numberline {2.1.2}Further settings}{10}{subsubsection.2.1.2}
\contentsline {subsubsection}{\numberline {2.1.3}Accessing a learning task}{10}{subsubsection.2.1.3}
\contentsline {subsubsection}{\numberline {2.1.4}Modifying a learning task}{13}{subsubsection.2.1.4}
\contentsline {subsubsection}{\numberline {2.1.5}Example tasks and convenience functions}{14}{subsubsection.2.1.5}
\contentsline {subsection}{\numberline {2.2}Learners}{14}{subsection.2.2}
\contentsline {subsubsection}{\numberline {2.2.1}Constructing a learner}{15}{subsubsection.2.2.1}
\contentsline {subsubsection}{\numberline {2.2.2}Accessing a learner}{16}{subsubsection.2.2.2}
\contentsline {subsubsection}{\numberline {2.2.3}Modifying a learner}{18}{subsubsection.2.2.3}
\contentsline {subsubsection}{\numberline {2.2.4}Listing learners}{19}{subsubsection.2.2.4}
\contentsline {subsection}{\numberline {2.3}Predicting Outcomes for New Data}{20}{subsection.2.3}
\contentsline {subsubsection}{\numberline {2.3.1}Accessing the prediction}{21}{subsubsection.2.3.1}
\contentsline {paragraph}{\numberline {2.3.1.1}Regression: Extracting standard errors}{22}{paragraph.2.3.1.1}
\contentsline {paragraph}{\numberline {2.3.1.2}Classification and clustering: Extracting probabilities}{23}{paragraph.2.3.1.2}
\contentsline {paragraph}{\numberline {2.3.1.3}Classification: Confusion matrix}{25}{paragraph.2.3.1.3}
\contentsline {subsubsection}{\numberline {2.3.2}Classification: Adjusting the decision threshold}{26}{subsubsection.2.3.2}
\contentsline {subsubsection}{\numberline {2.3.3}Visualizing the prediction}{29}{subsubsection.2.3.3}
\contentsline {subsection}{\numberline {2.4}Evaluating Learner Performance}{32}{subsection.2.4}
\contentsline {subsubsection}{\numberline {2.4.1}Available performance measures}{32}{subsubsection.2.4.1}
\contentsline {subsubsection}{\numberline {2.4.2}Listing measures}{32}{subsubsection.2.4.2}
\contentsline {subsubsection}{\numberline {2.4.3}Calculate performance measures}{33}{subsubsection.2.4.3}
\contentsline {paragraph}{\numberline {2.4.3.1}Requirements of performance measures}{34}{paragraph.2.4.3.1}
\contentsline {subsubsection}{\numberline {2.4.4}Access a performance measure}{35}{subsubsection.2.4.4}
\contentsline {subsubsection}{\numberline {2.4.5}Binary classification}{35}{subsubsection.2.4.5}
\contentsline {paragraph}{\numberline {2.4.5.1}Plot performance versus threshold}{35}{paragraph.2.4.5.1}
\contentsline {paragraph}{\numberline {2.4.5.2}ROC measures}{36}{paragraph.2.4.5.2}
\contentsline {subsection}{\numberline {2.5}Resampling}{37}{subsection.2.5}
\contentsline {subsubsection}{\numberline {2.5.1}Defining the resampling strategy}{37}{subsubsection.2.5.1}
\contentsline {subsubsection}{\numberline {2.5.2}Performing the resampling}{39}{subsubsection.2.5.2}
\contentsline {subsubsection}{\numberline {2.5.3}Accessing resample results}{42}{subsubsection.2.5.3}
\contentsline {paragraph}{\numberline {2.5.3.1}Predictions}{42}{paragraph.2.5.3.1}
\contentsline {paragraph}{\numberline {2.5.3.2}Learner models}{44}{paragraph.2.5.3.2}
\contentsline {paragraph}{\numberline {2.5.3.3}The extract option}{45}{paragraph.2.5.3.3}
\contentsline {subsubsection}{\numberline {2.5.4}Stratification and blocking}{47}{subsubsection.2.5.4}
\contentsline {paragraph}{\numberline {2.5.4.1}Stratification with respect to the target variable(s)}{47}{paragraph.2.5.4.1}
\contentsline {paragraph}{\numberline {2.5.4.2}Stratification with respect to explanatory variables}{47}{paragraph.2.5.4.2}
\contentsline {paragraph}{\numberline {2.5.4.3}Blocking}{48}{paragraph.2.5.4.3}
\contentsline {subsubsection}{\numberline {2.5.5}Resample descriptions and resample instances}{48}{subsubsection.2.5.5}
\contentsline {subsubsection}{\numberline {2.5.6}Aggregating performance values}{51}{subsubsection.2.5.6}
\contentsline {paragraph}{\numberline {2.5.6.1}Example: One measure with different aggregations}{52}{paragraph.2.5.6.1}
\contentsline {paragraph}{\numberline {2.5.6.2}Example: Calculating the training error}{53}{paragraph.2.5.6.2}
\contentsline {paragraph}{\numberline {2.5.6.3}Example: Bootstrap}{54}{paragraph.2.5.6.3}
\contentsline {subsubsection}{\numberline {2.5.7}Convenience functions}{54}{subsubsection.2.5.7}
\contentsline {subsection}{\numberline {2.6}Tuning Hyperparameters}{56}{subsection.2.6}
\contentsline {subsubsection}{\numberline {2.6.1}Specifying the search space}{56}{subsubsection.2.6.1}
\contentsline {subsubsection}{\numberline {2.6.2}Specifying the optimization algorithm}{57}{subsubsection.2.6.2}
\contentsline {subsubsection}{\numberline {2.6.3}Performing the tuning}{58}{subsubsection.2.6.3}
\contentsline {subsubsection}{\numberline {2.6.4}Accessing the tuning result}{61}{subsubsection.2.6.4}
\contentsline {subsubsection}{\numberline {2.6.5}Investigating hyperparameter tuning effects}{62}{subsubsection.2.6.5}
\contentsline {subsubsection}{\numberline {2.6.6}Further comments}{64}{subsubsection.2.6.6}
\contentsline {subsection}{\numberline {2.7}Benchmark Experiments}{64}{subsection.2.7}
\contentsline {subsubsection}{\numberline {2.7.1}Conducting benchmark experiments}{64}{subsubsection.2.7.1}
\contentsline {paragraph}{\numberline {2.7.1.1}Making experiments reproducible}{66}{paragraph.2.7.1.1}
\contentsline {subsubsection}{\numberline {2.7.2}Accessing benchmark results}{66}{subsubsection.2.7.2}
\contentsline {paragraph}{\numberline {2.7.2.1}Learner performances}{66}{paragraph.2.7.2.1}
\contentsline {paragraph}{\numberline {2.7.2.2}Predictions}{68}{paragraph.2.7.2.2}
\contentsline {paragraph}{\numberline {2.7.2.3}IDs}{69}{paragraph.2.7.2.3}
\contentsline {paragraph}{\numberline {2.7.2.4}Fitted models}{69}{paragraph.2.7.2.4}
\contentsline {paragraph}{\numberline {2.7.2.5}Learners and measures}{70}{paragraph.2.7.2.5}
\contentsline {subsubsection}{\numberline {2.7.3}Merging benchmark results}{71}{subsubsection.2.7.3}
\contentsline {subsubsection}{\numberline {2.7.4}Benchmark analysis and visualization}{72}{subsubsection.2.7.4}
\contentsline {paragraph}{\numberline {2.7.4.1}Example: Comparing lda, rpart and random Forest}{73}{paragraph.2.7.4.1}
\contentsline {paragraph}{\numberline {2.7.4.2}Integrated plots}{74}{paragraph.2.7.4.2}
\contentsline {subparagraph}{\numberline {2.7.4.2.1}Visualizing performances}{74}{subparagraph.2.7.4.2.1}
\contentsline {subparagraph}{\numberline {2.7.4.2.2}Visualizing aggregated performances}{78}{subparagraph.2.7.4.2.2}
\contentsline {subparagraph}{\numberline {2.7.4.2.3}Calculating and visualizing ranks}{78}{subparagraph.2.7.4.2.3}
\contentsline {paragraph}{\numberline {2.7.4.3}Comparing learners using hypothesis tests}{80}{paragraph.2.7.4.3}
\contentsline {paragraph}{\numberline {2.7.4.4}Critical differences diagram}{81}{paragraph.2.7.4.4}
\contentsline {paragraph}{\numberline {2.7.4.5}Custom plots}{83}{paragraph.2.7.4.5}
\contentsline {subsubsection}{\numberline {2.7.5}Further comments}{85}{subsubsection.2.7.5}
\contentsline {subsection}{\numberline {2.8}Parallelization}{86}{subsection.2.8}
\contentsline {subsubsection}{\numberline {2.8.1}Parallelization levels}{87}{subsubsection.2.8.1}
\contentsline {subsubsection}{\numberline {2.8.2}Custom learners and parallelization}{87}{subsubsection.2.8.2}
\contentsline {subsubsection}{\numberline {2.8.3}The end}{87}{subsubsection.2.8.3}
\contentsline {subsection}{\numberline {2.9}Visualization}{87}{subsection.2.9}
\contentsline {subsubsection}{\numberline {2.9.1}Generation and plotting functions}{87}{subsubsection.2.9.1}
\contentsline {paragraph}{\numberline {2.9.1.1}Some examples}{88}{paragraph.2.9.1.1}
\contentsline {paragraph}{\numberline {2.9.1.2}Customizing plots}{89}{paragraph.2.9.1.2}
\contentsline {subsubsection}{\numberline {2.9.2}Available generation and plotting functions}{94}{subsubsection.2.9.2}
\contentsline {section}{\numberline {3}Advanced}{95}{section.3}
\contentsline {subsection}{\numberline {3.1}Configuring mlr}{95}{subsection.3.1}
\contentsline {subsubsection}{\numberline {3.1.1}Example: Reducing the output on the console}{95}{subsubsection.3.1.1}
\contentsline {subsubsection}{\numberline {3.1.2}Accessing and resetting the configuration}{96}{subsubsection.3.1.2}
\contentsline {subsubsection}{\numberline {3.1.3}Example: Turning off parameter checking}{97}{subsubsection.3.1.3}
\contentsline {subsubsection}{\numberline {3.1.4}Example: Handling errors in a learning method}{98}{subsubsection.3.1.4}
\contentsline {subsection}{\numberline {3.2}Wrapper}{99}{subsection.3.2}
\contentsline {subsubsection}{\numberline {3.2.1}Example: Bagging wrapper}{100}{subsubsection.3.2.1}
\contentsline {subsection}{\numberline {3.3}Data Preprocessing}{104}{subsection.3.3}
\contentsline {subsubsection}{\numberline {3.3.1}Fusing learners with preprocessing}{105}{subsubsection.3.3.1}
\contentsline {subsubsection}{\numberline {3.3.2}Preprocessing with makePreprocWrapperCaret}{105}{subsubsection.3.3.2}
\contentsline {paragraph}{\numberline {3.3.2.1}Joint tuning of preprocessing options and learner parameters}{108}{paragraph.3.3.2.1}
\contentsline {subsubsection}{\numberline {3.3.3}Writing a custom preprocessing wrapper}{110}{subsubsection.3.3.3}
\contentsline {paragraph}{\numberline {3.3.3.1}Specifying the train function}{110}{paragraph.3.3.3.1}
\contentsline {paragraph}{\numberline {3.3.3.2}Specifying the predict function}{111}{paragraph.3.3.3.2}
\contentsline {paragraph}{\numberline {3.3.3.3}Creating the preprocessing wrapper}{111}{paragraph.3.3.3.3}
\contentsline {paragraph}{\numberline {3.3.3.4}Joint tuning of preprocessing and learner parameters}{112}{paragraph.3.3.3.4}
\contentsline {paragraph}{\numberline {3.3.3.5}Preprocessing wrapper functions}{114}{paragraph.3.3.3.5}
\contentsline {subsection}{\numberline {3.4}Imputation of Missing Values}{115}{subsection.3.4}
\contentsline {subsubsection}{\numberline {3.4.1}Imputation and reimputation}{115}{subsubsection.3.4.1}
\contentsline {subsubsection}{\numberline {3.4.2}Fusing a learner with imputation}{119}{subsubsection.3.4.2}
\contentsline {subsection}{\numberline {3.5}Generic Bagging}{120}{subsection.3.5}
\contentsline {subsubsection}{\numberline {3.5.1}Changing the type of prediction}{121}{subsubsection.3.5.1}
\contentsline {subsection}{\numberline {3.6}Iterated F-Racing for mixed spaces and dependencies}{123}{subsection.3.6}
\contentsline {subsubsection}{\numberline {3.6.1}Tuning across whole model spaces with ModelMultiplexer}{124}{subsubsection.3.6.1}
\contentsline {subsubsection}{\numberline {3.6.2}Multi-criteria evaluation and optimization}{125}{subsubsection.3.6.2}
\contentsline {subsection}{\numberline {3.7}Feature Selection}{126}{subsection.3.7}
\contentsline {subsubsection}{\numberline {3.7.1}Filter methods}{126}{subsubsection.3.7.1}
\contentsline {paragraph}{\numberline {3.7.1.1}Calculating the feature importance}{126}{paragraph.3.7.1.1}
\contentsline {paragraph}{\numberline {3.7.1.2}Selecting a feature subset}{128}{paragraph.3.7.1.2}
\contentsline {paragraph}{\numberline {3.7.1.3}Fuse a learner with a filter method}{129}{paragraph.3.7.1.3}
\contentsline {paragraph}{\numberline {3.7.1.4}Tuning the size of the feature subset}{130}{paragraph.3.7.1.4}
\contentsline {subsubsection}{\numberline {3.7.2}Wrapper methods}{133}{subsubsection.3.7.2}
\contentsline {paragraph}{\numberline {3.7.2.1}Select a feature subset}{133}{paragraph.3.7.2.1}
\contentsline {paragraph}{\numberline {3.7.2.2}Fuse a learner with feature selection}{135}{paragraph.3.7.2.2}
\contentsline {subsection}{\numberline {3.8}Nested Resampling}{137}{subsection.3.8}
\contentsline {subsubsection}{\numberline {3.8.1}Tuning}{138}{subsubsection.3.8.1}
\contentsline {paragraph}{\numberline {3.8.1.1}Accessing the tuning result}{139}{paragraph.3.8.1.1}
\contentsline {subsubsection}{\numberline {3.8.2}Feature selection}{140}{subsubsection.3.8.2}
\contentsline {paragraph}{\numberline {3.8.2.1}Wrapper methods}{141}{paragraph.3.8.2.1}
\contentsline {subparagraph}{\numberline {3.8.2.1.1}Accessing the selected features}{141}{subparagraph.3.8.2.1.1}
\contentsline {paragraph}{\numberline {3.8.2.2}Filter methods with tuning}{143}{paragraph.3.8.2.2}
\contentsline {subparagraph}{\numberline {3.8.2.2.1}Accessing the selected features and optimal percentage}{143}{subparagraph.3.8.2.2.1}
\contentsline {subsubsection}{\numberline {3.8.3}Benchmark experiments}{145}{subsubsection.3.8.3}
\contentsline {paragraph}{\numberline {3.8.3.1}Example 1: Two tasks, two learners, tuning}{145}{paragraph.3.8.3.1}
\contentsline {paragraph}{\numberline {3.8.3.2}Example 2: One task, two learners, feature selection}{148}{paragraph.3.8.3.2}
\contentsline {paragraph}{\numberline {3.8.3.3}Example 3: One task, two learners, feature filtering with tuning}{150}{paragraph.3.8.3.3}
\contentsline {subsection}{\numberline {3.9}Cost-Sensitive Classification}{151}{subsection.3.9}
\contentsline {subsubsection}{\numberline {3.9.1}Class-dependent misclassification costs}{151}{subsubsection.3.9.1}
\contentsline {paragraph}{\numberline {3.9.1.1}Binary classification problems}{151}{paragraph.3.9.1.1}
\contentsline {subparagraph}{\numberline {3.9.1.1.1}1. Thresholding}{153}{subparagraph.3.9.1.1.1}
\contentsline {subparagraph}{\numberline {3.9.1.1.2}2. Rebalancing}{156}{subparagraph.3.9.1.1.2}
\contentsline {paragraph}{\numberline {3.9.1.2}Multi-class problems}{160}{paragraph.3.9.1.2}
\contentsline {subparagraph}{\numberline {3.9.1.2.1}1. Thresholding}{161}{subparagraph.3.9.1.2.1}
\contentsline {subparagraph}{\numberline {3.9.1.2.2}2. Rebalancing}{162}{subparagraph.3.9.1.2.2}
\contentsline {subsubsection}{\numberline {3.9.2}Example-dependent misclassification costs}{163}{subsubsection.3.9.2}
\contentsline {subsection}{\numberline {3.10}Imbalanced Classification Problems}{165}{subsection.3.10}
\contentsline {subsubsection}{\numberline {3.10.1}Sampling-based approaches}{165}{subsubsection.3.10.1}
\contentsline {paragraph}{\numberline {3.10.1.1}(Simple) over- and undersampling}{165}{paragraph.3.10.1.1}
\contentsline {paragraph}{\numberline {3.10.1.2}Over- and undersampling wrappers}{167}{paragraph.3.10.1.2}
\contentsline {paragraph}{\numberline {3.10.1.3}Extensions to oversampling}{167}{paragraph.3.10.1.3}
\contentsline {subparagraph}{\numberline {3.10.1.3.1}1. SMOTE (Synthetic Minority Oversampling Technique)}{167}{subparagraph.3.10.1.3.1}
\contentsline {subparagraph}{\numberline {3.10.1.3.2}2. Overbagging}{168}{subparagraph.3.10.1.3.2}
\contentsline {subsubsection}{\numberline {3.10.2}Cost-based approaches}{169}{subsubsection.3.10.2}
\contentsline {paragraph}{\numberline {3.10.2.1}Weighted classes wrapper}{170}{paragraph.3.10.2.1}
\contentsline {subsection}{\numberline {3.11}ROC Analysis and Performance Curves}{170}{subsection.3.11}
\contentsline {subsubsection}{\numberline {3.11.1}Performance plots with plotROCCurves}{171}{subsubsection.3.11.1}
\contentsline {paragraph}{\numberline {3.11.1.1}Example 1: Single predictions}{171}{paragraph.3.11.1.1}
\contentsline {paragraph}{\numberline {3.11.1.2}Example 2: Benchmark experiment}{175}{paragraph.3.11.1.2}
\contentsline {subsubsection}{\numberline {3.11.2}Performance plots with asROCRPrediction}{179}{subsubsection.3.11.2}
\contentsline {paragraph}{\numberline {3.11.2.1}Example 1: Single predictions (continued)}{180}{paragraph.3.11.2.1}
\contentsline {paragraph}{\numberline {3.11.2.2}Example 2: Benchmark experiments (continued)}{181}{paragraph.3.11.2.2}
\contentsline {subsubsection}{\numberline {3.11.3}Viper charts}{183}{subsubsection.3.11.3}
\contentsline {subsection}{\numberline {3.12}Multilabel Classification}{183}{subsection.3.12}
\contentsline {subsubsection}{\numberline {3.12.1}Creating a task}{184}{subsubsection.3.12.1}
\contentsline {subsubsection}{\numberline {3.12.2}Constructing a learner}{184}{subsubsection.3.12.2}
\contentsline {paragraph}{\numberline {3.12.2.1}Algorithm adaptation methods}{184}{paragraph.3.12.2.1}
\contentsline {paragraph}{\numberline {3.12.2.2}Problem transformation methods}{185}{paragraph.3.12.2.2}
\contentsline {subparagraph}{\numberline {3.12.2.2.1}Binary relevance}{185}{subparagraph.3.12.2.2.1}
\contentsline {subparagraph}{\numberline {3.12.2.2.2}Classifier chains}{185}{subparagraph.3.12.2.2.2}
\contentsline {subparagraph}{\numberline {3.12.2.2.3}Nested stacking}{186}{subparagraph.3.12.2.2.3}
\contentsline {subparagraph}{\numberline {3.12.2.2.4}Dependent binary relevance}{186}{subparagraph.3.12.2.2.4}
\contentsline {subparagraph}{\numberline {3.12.2.2.5}Stacking}{186}{subparagraph.3.12.2.2.5}
\contentsline {subsubsection}{\numberline {3.12.3}Train}{186}{subsubsection.3.12.3}
\contentsline {subsubsection}{\numberline {3.12.4}Predict}{186}{subsubsection.3.12.4}
\contentsline {subsubsection}{\numberline {3.12.5}Performance}{187}{subsubsection.3.12.5}
\contentsline {subsubsection}{\numberline {3.12.6}Resampling}{188}{subsubsection.3.12.6}
\contentsline {subsubsection}{\numberline {3.12.7}Binary performance}{188}{subsubsection.3.12.7}
\contentsline {subsection}{\numberline {3.13}Learning Curve Analysis}{189}{subsection.3.13}
\contentsline {subsubsection}{\numberline {3.13.1}Plotting the learning curve}{189}{subsubsection.3.13.1}
\contentsline {subsection}{\numberline {3.14}Exploring Learner Predictions}{192}{subsection.3.14}
\contentsline {subsubsection}{\numberline {3.14.1}Generating partial dependences}{193}{subsubsection.3.14.1}
\contentsline {subsubsection}{\numberline {3.14.2}Functional ANOVA}{199}{subsubsection.3.14.2}
\contentsline {subsubsection}{\numberline {3.14.3}Plotting partial dependences}{200}{subsubsection.3.14.3}
\contentsline {subsection}{\numberline {3.15}Classifier Calibration}{207}{subsection.3.15}
\contentsline {subsection}{\numberline {3.16}Evaluating Hyperparameter Tuning}{211}{subsection.3.16}
\contentsline {subsubsection}{\numberline {3.16.1}Generating hyperparameter tuning data}{212}{subsubsection.3.16.1}
\contentsline {subsubsection}{\numberline {3.16.2}Visualizing the effect of a single hyperparameter}{214}{subsubsection.3.16.2}
\contentsline {subsubsection}{\numberline {3.16.3}Visualizing the effect of 2 hyperparameters}{217}{subsubsection.3.16.3}
\contentsline {subsubsection}{\numberline {3.16.4}Visualizing the effects of more than 2 hyperparameters}{222}{subsubsection.3.16.4}
\contentsline {subsection}{\numberline {3.17}Out-of-Bag Predictions}{224}{subsection.3.17}
\contentsline {subsection}{\numberline {3.18}Handling of Spatial Data}{225}{subsection.3.18}
\contentsline {subsubsection}{\numberline {3.18.1}Introduction}{225}{subsubsection.3.18.1}
\contentsline {subsubsection}{\numberline {3.18.2}How to use spatial partitioning in mlr}{226}{subsubsection.3.18.2}
\contentsline {subsubsection}{\numberline {3.18.3}Examples}{226}{subsubsection.3.18.3}
\contentsline {paragraph}{\numberline {3.18.3.1}Spatial Cross-Validation}{227}{paragraph.3.18.3.1}
\contentsline {paragraph}{\numberline {3.18.3.2}Non-Spatial Cross-Validation}{229}{paragraph.3.18.3.2}
\contentsline {subsubsection}{\numberline {3.18.4}Notes}{233}{subsubsection.3.18.4}
\contentsline {section}{\numberline {4}Extending}{233}{section.4}
\contentsline {subsection}{\numberline {4.1}Integrating Another Learner}{233}{subsection.4.1}
\contentsline {subsubsection}{\numberline {4.1.1}Classes, constructors, and naming schemes}{233}{subsubsection.4.1.1}
\contentsline {subsubsection}{\numberline {4.1.2}Classification}{234}{subsubsection.4.1.2}
\contentsline {paragraph}{\numberline {4.1.2.1}Definition of the learner}{234}{paragraph.4.1.2.1}
\contentsline {paragraph}{\numberline {4.1.2.2}Creating the training function of the learner}{235}{paragraph.4.1.2.2}
\contentsline {paragraph}{\numberline {4.1.2.3}Creating the prediction method}{236}{paragraph.4.1.2.3}
\contentsline {subsubsection}{\numberline {4.1.3}Regression}{236}{subsubsection.4.1.3}
\contentsline {subsubsection}{\numberline {4.1.4}Survival analysis}{237}{subsubsection.4.1.4}
\contentsline {subsubsection}{\numberline {4.1.5}Clustering}{238}{subsubsection.4.1.5}
\contentsline {subsubsection}{\numberline {4.1.6}Multilabel classification}{239}{subsubsection.4.1.6}
\contentsline {subsubsection}{\numberline {4.1.7}Creating a new method for extracting feature importance values}{240}{subsubsection.4.1.7}
\contentsline {subsubsection}{\numberline {4.1.8}Creating a new method for extracting out-of-bag predictions}{240}{subsubsection.4.1.8}
\contentsline {subsubsection}{\numberline {4.1.9}Registering your learner}{241}{subsubsection.4.1.9}
\contentsline {subsubsection}{\numberline {4.1.10}Further information for developers}{241}{subsubsection.4.1.10}
\contentsline {paragraph}{\numberline {4.1.10.1}Unit testing}{242}{paragraph.4.1.10.1}
\contentsline {subsection}{\numberline {4.2}Integrating Another Measure}{244}{subsection.4.2}
\contentsline {subsubsection}{\numberline {4.2.1}Performance measures and aggregation schemes}{244}{subsubsection.4.2.1}
\contentsline {subsubsection}{\numberline {4.2.2}Constructing a performance measure}{246}{subsubsection.4.2.2}
\contentsline {subsubsection}{\numberline {4.2.3}Constructing a measure for ordinary misclassification costs}{246}{subsubsection.4.2.3}
\contentsline {subsubsection}{\numberline {4.2.4}Creating an aggregation scheme}{247}{subsubsection.4.2.4}
\contentsline {paragraph}{\numberline {4.2.4.1}Example: Evaluating the range of measures}{247}{paragraph.4.2.4.1}
\contentsline {subsection}{\numberline {4.3}Creating an Imputation Method}{249}{subsection.4.3}
\contentsline {subsubsection}{\numberline {4.3.1}Example: Imputation using the mean}{249}{subsubsection.4.3.1}
\contentsline {subsubsection}{\numberline {4.3.2}Writing your own imputation method}{250}{subsubsection.4.3.2}
\contentsline {subsection}{\numberline {4.4}Integrating Another Filter Method}{251}{subsection.4.4}
\contentsline {subsubsection}{\numberline {4.4.1}Filter objects}{251}{subsubsection.4.4.1}
\contentsline {subsubsection}{\numberline {4.4.2}Writing a new filter method}{252}{subsubsection.4.4.2}
\contentsline {section}{\numberline {5}Appendix}{255}{section.5}
\contentsline {subsection}{\numberline {5.1}Example Tasks}{255}{subsection.5.1}
\contentsline {subsection}{\numberline {5.2}Integrated Learners}{255}{subsection.5.2}
\contentsline {paragraph}{\numberline {5.2.0.1}Classification (84)}{255}{paragraph.5.2.0.1}
\contentsline {paragraph}{\numberline {5.2.0.2}Regression (61)}{257}{paragraph.5.2.0.2}
\contentsline {paragraph}{\numberline {5.2.0.3}Survival analysis (12)}{258}{paragraph.5.2.0.3}
\contentsline {paragraph}{\numberline {5.2.0.4}Cluster analysis (9)}{259}{paragraph.5.2.0.4}
\contentsline {paragraph}{\numberline {5.2.0.5}Cost-sensitive classification}{259}{paragraph.5.2.0.5}
\contentsline {paragraph}{\numberline {5.2.0.6}Multilabel classification (3)}{259}{paragraph.5.2.0.6}
\contentsline {subsection}{\numberline {5.3}Implemented Performance Measures}{260}{subsection.5.3}
\contentsline {paragraph}{\numberline {5.3.0.1}Classification}{260}{paragraph.5.3.0.1}
\contentsline {paragraph}{\numberline {5.3.0.2}Regression}{261}{paragraph.5.3.0.2}
\contentsline {paragraph}{\numberline {5.3.0.3}Survival analysis}{261}{paragraph.5.3.0.3}
\contentsline {paragraph}{\numberline {5.3.0.4}Cluster analysis}{261}{paragraph.5.3.0.4}
\contentsline {paragraph}{\numberline {5.3.0.5}Cost-sensitive classification}{262}{paragraph.5.3.0.5}
\contentsline {paragraph}{\numberline {5.3.0.6}Multilabel classification}{262}{paragraph.5.3.0.6}
\contentsline {paragraph}{\numberline {5.3.0.7}General performance measures}{262}{paragraph.5.3.0.7}
\contentsline {subsection}{\numberline {5.4}Feature Selection}{262}{subsection.5.4}
\contentsline {subsubsection}{\numberline {5.4.1}Current methods}{262}{subsubsection.5.4.1}
\contentsline {subsubsection}{\numberline {5.4.2}Deprecated methods}{263}{subsubsection.5.4.2}
